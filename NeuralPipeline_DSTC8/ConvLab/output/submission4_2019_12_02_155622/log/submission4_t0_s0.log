[2019-12-02 15:56:22,941 PID:2591 INFO archival.py load_archive] loading archive file /home/donghoon/.convlab/cache/35863b26c71cbed669f08d3e50030aed24e84e833eb523378b67226d137bedd9.f494dce99f30d2e1786136f7a0a487e643ee8ac430423828d1c0013526d1d7bd
[2019-12-02 15:56:22,944 PID:2591 INFO archival.py load_archive] extracting archive file /home/donghoon/.convlab/cache/35863b26c71cbed669f08d3e50030aed24e84e833eb523378b67226d137bedd9.f494dce99f30d2e1786136f7a0a487e643ee8ac430423828d1c0013526d1d7bd to temp dir /tmp/tmplf3nj001
[2019-12-02 15:56:23,033 PID:2591 INFO params.py pop] type = default
[2019-12-02 15:56:23,033 PID:2591 INFO vocabulary.py from_files] Loading token dictionary from /tmp/tmplf3nj001/vocabulary.
[2019-12-02 15:56:23,046 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.models.model.Model'> from params {'attention': {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400}, 'attention_for_intent': False, 'attention_for_tag': False, 'context_for_intent': True, 'context_for_tag': False, 'dropout': 0.3, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'}, 'include_start_end_transitions': False, 'intent_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'}, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}}, 'type': 'milu'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,046 PID:2591 INFO params.py pop] model.type = milu
[2019-12-02 15:56:23,047 PID:2591 INFO from_params.py from_params] instantiating class <class 'convlab.modules.nlu.multiwoz.milu.model.MILU'> from params {'attention': {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400}, 'attention_for_intent': False, 'attention_for_tag': False, 'context_for_intent': True, 'context_for_tag': False, 'dropout': 0.3, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'}, 'include_start_end_transitions': False, 'intent_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'}, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}}} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,047 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,047 PID:2591 INFO params.py pop] model.text_field_embedder.type = basic
[2019-12-02 15:56:23,047 PID:2591 INFO params.py pop] model.text_field_embedder.embedder_to_indexer_map = None
[2019-12-02 15:56:23,047 PID:2591 INFO params.py pop] model.text_field_embedder.allow_unmatched_keys = False
[2019-12-02 15:56:23,048 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.type = character_encoding
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 16
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
[2019-12-02 15:56:23,048 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
[2019-12-02 15:56:23,049 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
[2019-12-02 15:56:23,049 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'} and extras {}
[2019-12-02 15:56:23,049 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
[2019-12-02 15:56:23,049 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128} and extras {}
[2019-12-02 15:56:23,049 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 16
[2019-12-02 15:56:23,050 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 128
[2019-12-02 15:56:23,050 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
[2019-12-02 15:56:23,050 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
[2019-12-02 15:56:23,050 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
[2019-12-02 15:56:23,052 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.type = embedding
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.num_embeddings = None
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.embedding_dim = 50
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.pretrained_file = None
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.projection_dim = None
[2019-12-02 15:56:23,052 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.trainable = True
[2019-12-02 15:56:23,053 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.padding_index = None
[2019-12-02 15:56:23,053 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.max_norm = None
[2019-12-02 15:56:23,053 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.norm_type = 2.0
[2019-12-02 15:56:23,053 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False
[2019-12-02 15:56:23,053 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.sparse = False
[2019-12-02 15:56:23,059 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,059 PID:2591 INFO params.py pop] model.encoder.type = lstm
[2019-12-02 15:56:23,059 PID:2591 INFO params.py pop] model.encoder.batch_first = True
[2019-12-02 15:56:23,059 PID:2591 INFO params.py pop] model.encoder.stateful = False
[2019-12-02 15:56:23,060 PID:2591 INFO params.py as_dict] Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
[2019-12-02 15:56:23,060 PID:2591 INFO params.py as_dict] CURRENTLY DEFINED PARAMETERS: 
[2019-12-02 15:56:23,060 PID:2591 INFO params.py log_recursively] model.encoder.bidirectional = True
[2019-12-02 15:56:23,060 PID:2591 INFO params.py log_recursively] model.encoder.dropout = 0.5
[2019-12-02 15:56:23,060 PID:2591 INFO params.py log_recursively] model.encoder.hidden_size = 200
[2019-12-02 15:56:23,060 PID:2591 INFO params.py log_recursively] model.encoder.input_size = 178
[2019-12-02 15:56:23,060 PID:2591 INFO params.py log_recursively] model.encoder.num_layers = 1
[2019-12-02 15:56:23,060 PID:2591 INFO params.py log_recursively] model.encoder.batch_first = True
[2019-12-02 15:56:23,065 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,065 PID:2591 INFO params.py pop] model.intent_encoder.type = lstm
[2019-12-02 15:56:23,065 PID:2591 INFO params.py pop] model.intent_encoder.batch_first = True
[2019-12-02 15:56:23,065 PID:2591 INFO params.py pop] model.intent_encoder.stateful = False
[2019-12-02 15:56:23,065 PID:2591 INFO params.py as_dict] Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
[2019-12-02 15:56:23,065 PID:2591 INFO params.py as_dict] CURRENTLY DEFINED PARAMETERS: 
[2019-12-02 15:56:23,065 PID:2591 INFO params.py log_recursively] model.intent_encoder.bidirectional = True
[2019-12-02 15:56:23,065 PID:2591 INFO params.py log_recursively] model.intent_encoder.dropout = 0.5
[2019-12-02 15:56:23,065 PID:2591 INFO params.py log_recursively] model.intent_encoder.hidden_size = 200
[2019-12-02 15:56:23,066 PID:2591 INFO params.py log_recursively] model.intent_encoder.input_size = 400
[2019-12-02 15:56:23,066 PID:2591 INFO params.py log_recursively] model.intent_encoder.num_layers = 1
[2019-12-02 15:56:23,066 PID:2591 INFO params.py log_recursively] model.intent_encoder.batch_first = True
[2019-12-02 15:56:23,072 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,072 PID:2591 INFO params.py pop] model.attention.type = bilinear
[2019-12-02 15:56:23,072 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.attention.bilinear_attention.BilinearAttention'> from params {'matrix_dim': 400, 'vector_dim': 400} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:23,073 PID:2591 INFO params.py pop] model.attention.vector_dim = 400
[2019-12-02 15:56:23,073 PID:2591 INFO params.py pop] model.attention.matrix_dim = 400
[2019-12-02 15:56:23,073 PID:2591 INFO params.py pop] model.attention.normalize = True
[2019-12-02 15:56:23,074 PID:2591 INFO params.py pop] model.context_for_intent = True
[2019-12-02 15:56:23,074 PID:2591 INFO params.py pop] model.context_for_tag = False
[2019-12-02 15:56:23,074 PID:2591 INFO params.py pop] model.attention_for_intent = False
[2019-12-02 15:56:23,074 PID:2591 INFO params.py pop] model.attention_for_tag = False
[2019-12-02 15:56:23,074 PID:2591 INFO params.py pop] model.sequence_label_namespace = labels
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.intent_label_namespace = intent_labels
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.label_encoding = BIO
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.include_start_end_transitions = False
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.crf_decoding = False
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.constrain_crf_decoding = None
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.focal_loss_gamma = None
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.nongeneral_intent_weight = 5.0
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.num_train_examples = None
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.calculate_span_f1 = None
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.dropout = 0.3
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.verbose_metrics = False
[2019-12-02 15:56:23,075 PID:2591 INFO params.py pop] model.regularizer = [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]]
[2019-12-02 15:56:23,076 PID:2591 INFO params.py pop] model.regularizer.list.list.type = l2
[2019-12-02 15:56:23,131 PID:2591 INFO initializers.py __call__] Initializing parameters
[2019-12-02 15:56:23,131 PID:2591 INFO initializers.py __call__] Done initializing parameters; the following parameters are using their default initialization from their code
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    attention._bias
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    attention._weight_matrix
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.bias_hh_l0
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.bias_hh_l0_reverse
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.bias_ih_l0
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.bias_ih_l0_reverse
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.weight_hh_l0
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.weight_hh_l0_reverse
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.weight_ih_l0
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    encoder._module.weight_ih_l0_reverse
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_hh_l0
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_hh_l0_reverse
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_ih_l0
[2019-12-02 15:56:23,132 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_ih_l0_reverse
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_hh_l0
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_hh_l0_reverse
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_ih_l0
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_ih_l0_reverse
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    intent_projection_layer.bias
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    intent_projection_layer.weight
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    tag_projection_layer._module.bias
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    tag_projection_layer._module.weight
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_token_characters._embedding._module.weight
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
[2019-12-02 15:56:23,133 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_tokens.weight
[2019-12-02 15:56:23,414 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'context_size': 5, 'token_indexers': {'token_characters': {'min_padding_length': 3, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'milu'} and extras {}
[2019-12-02 15:56:23,414 PID:2591 INFO params.py pop] dataset_reader.type = milu
[2019-12-02 15:56:23,414 PID:2591 INFO from_params.py from_params] instantiating class <class 'convlab.modules.nlu.multiwoz.milu.dataset_reader.MILUDatasetReader'> from params {'context_size': 5, 'token_indexers': {'token_characters': {'min_padding_length': 3, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras {}
[2019-12-02 15:56:23,414 PID:2591 INFO params.py pop] dataset_reader.context_size = 5
[2019-12-02 15:56:23,414 PID:2591 INFO params.py pop] dataset_reader.agent = None
[2019-12-02 15:56:23,415 PID:2591 INFO params.py pop] dataset_reader.random_context_size = True
[2019-12-02 15:56:23,415 PID:2591 INFO params.py pop] dataset_reader.token_delimiter = None
[2019-12-02 15:56:23,415 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'min_padding_length': 3, 'type': 'characters'} and extras {}
[2019-12-02 15:56:23,415 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.type = characters
[2019-12-02 15:56:23,415 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer from params {'min_padding_length': 3} and extras {}
[2019-12-02 15:56:23,415 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.namespace = token_characters
[2019-12-02 15:56:23,415 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.start_tokens = None
[2019-12-02 15:56:23,415 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.end_tokens = None
[2019-12-02 15:56:23,415 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.min_padding_length = 3
[2019-12-02 15:56:23,415 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras {}
[2019-12-02 15:56:23,416 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.type = single_id
[2019-12-02 15:56:23,416 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras {}
[2019-12-02 15:56:23,416 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.namespace = tokens
[2019-12-02 15:56:23,416 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.lowercase_tokens = True
[2019-12-02 15:56:23,416 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.start_tokens = None
[2019-12-02 15:56:23,416 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.end_tokens = None
[2019-12-02 15:56:23,416 PID:2591 INFO params.py pop] dataset_reader.lazy = False
[2019-12-02 15:56:23,450 PID:2591 INFO multiwoz.py __init__] MultiWozEnv:
- e = 0
- done = False
- env_spec = {'evaluator': {'name': 'MultiWozEvaluator'},
 'max_frame': 1000,
 'max_t': 40,
 'name': 'multiwoz',
 'nlg': {'is_user': True, 'name': 'MultiwozTemplateNLG'},
 'nlu': {'model_file': 'https://convlab.blob.core.windows.net/models/milu.tar.gz',
         'name': 'MILU'},
 'sys_policy': {'name': 'RuleBasedMultiwozBot'},
 'user_policy': {'name': 'UserPolicyAgendaMultiWoz'}}
- log_frequency = None
- frame_op = None
- frame_op_len = None
- normalize_state = False
- reward_scale = None
- num_envs = 1
- eval_frequency = 100
- name = multiwoz
- max_t = 40
- max_frame = 1000
- is_venv = False
- clock_speed = 1
- clock = <convlab.env.base.Clock object at 0x7fa1ee1531d0>
- to_render = False
- action_dim = 0
- observation_dim = 0
- u_env = <convlab.env.multiwoz.MultiWozEnvironment object at 0x7fa1ee153470>
- evaluator = <convlab.evaluator.multiwoz.MultiWozEvaluator object at 0x7fa1f5687860>
- observation_space = Box(0,)
- action_space = Discrete(0)
- observable_dim = {'state': 0}
- is_discrete = True
[2019-12-02 15:56:23,457 PID:2591 INFO modeling_utils.py from_pretrained] loading configuration file models/v4_1/config.json
[2019-12-02 15:56:23,457 PID:2591 INFO modeling_utils.py from_pretrained] Model config {
  "attn_pdrop": 0.1,
  "embd_pdrop": 0.1,
  "finetuning_task": null,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_layer": 12,
  "n_positions": 1024,
  "num_labels": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "resid_pdrop": 0.1,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "token_ids",
  "summary_use_proj": true,
  "torchscript": false,
  "vocab_size": 50365
}

[2019-12-02 15:56:23,458 PID:2591 INFO modeling_utils.py from_pretrained] loading weights file models/v4_1/pytorch_model.bin
[2019-12-02 15:56:26,820 PID:2591 INFO tokenization_utils.py _from_pretrained] Model name 'models/v4_1' not found in model shortcut name list (gpt2, gpt2-medium). Assuming 'models/v4_1' is a path or url to a directory containing tokenizer files.
[2019-12-02 15:56:26,820 PID:2591 INFO tokenization_utils.py _from_pretrained] Didn't find file models/v4_1/added_tokens.json. We won't load it.
[2019-12-02 15:56:26,820 PID:2591 INFO tokenization_utils.py _from_pretrained] Didn't find file models/v4_1/special_tokens_map.json. We won't load it.
[2019-12-02 15:56:26,820 PID:2591 INFO tokenization_utils.py _from_pretrained] loading file None
[2019-12-02 15:56:26,820 PID:2591 INFO tokenization_utils.py _from_pretrained] loading file None
[2019-12-02 15:56:26,820 PID:2591 INFO tokenization_utils.py _from_pretrained] loading file models/v4_1/vocab.json
[2019-12-02 15:56:26,821 PID:2591 INFO tokenization_utils.py _from_pretrained] loading file models/v4_1/merges.txt
[2019-12-02 15:56:26,887 PID:2591 INFO tokenization_utils.py add_tokens] Adding <bos> to the vocabulary
[2019-12-02 15:56:26,887 PID:2591 INFO tokenization_utils.py add_tokens] Adding <eos> to the vocabulary
[2019-12-02 15:56:26,887 PID:2591 INFO tokenization_utils.py add_tokens] Adding <user> to the vocabulary
[2019-12-02 15:56:26,887 PID:2591 INFO tokenization_utils.py add_tokens] Adding <system> to the vocabulary
[2019-12-02 15:56:26,887 PID:2591 INFO tokenization_utils.py add_tokens] Adding <cs> to the vocabulary
[2019-12-02 15:56:26,887 PID:2591 INFO tokenization_utils.py add_tokens] Adding <dp> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <pad> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <dc> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <nm> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <leave> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <people> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <arrive> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <pricerange> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <arriveby> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <ticket> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <dest> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <none> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <leaveat> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <car> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <ref> to the vocabulary
[2019-12-02 15:56:26,888 PID:2591 INFO tokenization_utils.py add_tokens] Adding <department> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <open> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <parking> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <departure> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <day> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <type> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <time> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <stay> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <internet> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <phone> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <choice> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <destination> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <name> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <addr> to the vocabulary
[2019-12-02 15:56:26,889 PID:2591 INFO tokenization_utils.py add_tokens] Adding <fee> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <area> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <post> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <price> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <depart> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <id> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <food> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <stars> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <restaurant-inform> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <restaurant-recommend> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <attraction-request> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hotel-request> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <general-welcome> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <train-offerbook> to the vocabulary
[2019-12-02 15:56:26,890 PID:2591 INFO tokenization_utils.py add_tokens] Adding <booking-request> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <restaurant-nooffer> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hospital-inform> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <train-request> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <train-nooffer> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <general-bye> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hotel-select> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <taxi-inform> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <attraction-select> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <attraction-nooffer> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <booking-inform> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <train-offerbooked> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <general-greet> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <train-inform> to the vocabulary
[2019-12-02 15:56:26,891 PID:2591 INFO tokenization_utils.py add_tokens] Adding <train-select> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <booking-nobook> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <police-inform> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <taxi-request> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <attraction-inform> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <restaurant-select> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hotel-recommend> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <booking-book> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hospital-request> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <general-reqmore> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <restaurant-request> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hotel-nooffer> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hotel-inform> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <attraction-recommend> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hotel> to the vocabulary
[2019-12-02 15:56:26,892 PID:2591 INFO tokenization_utils.py add_tokens] Adding <police> to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding <restaurant> to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding <train> to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding <hospital> to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding <taxi> to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding <attraction> to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [restaurant_phone] to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [restaurant_reference] to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [restaurant_postcode] to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [restaurant_addr] to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [restaurant_name] to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hotel_phone] to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hotel_reference] to the vocabulary
[2019-12-02 15:56:26,893 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hotel_postcode] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hotel_addr] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hotel_name] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [attraction_phone] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [attraction_postcode] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [attraction_addr] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [attraction_name] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [train_reference] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [train_id] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [taxi_phone] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hospital_phone] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hospital_postcode] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hospital_addr] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [hospital_name] to the vocabulary
[2019-12-02 15:56:26,894 PID:2591 INFO tokenization_utils.py add_tokens] Adding [police_phone] to the vocabulary
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_tokens] Adding [police_postcode] to the vocabulary
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_tokens] Adding [police_addr] to the vocabulary
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_tokens] Adding [police_name] to the vocabulary
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <bos> to the <bos> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <eos> to the <eos> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <user> to the <user> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <system> to the <system> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <cs> to the <cs> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <dp> to the <dp> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <pad> to the <pad> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <dc> to the <dc> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <nm> to the <nm> key of the tokenizer
[2019-12-02 15:56:26,895 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <leave> to the <leave> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <people> to the <people> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <arrive> to the <arrive> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <pricerange> to the <pricerange> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <arriveby> to the <arriveby> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <ticket> to the <ticket> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <dest> to the <dest> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <none> to the <none> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <leaveat> to the <leaveat> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <car> to the <car> key of the tokenizer
[2019-12-02 15:56:26,896 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <ref> to the <ref> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <department> to the <department> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <open> to the <open> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <parking> to the <parking> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <departure> to the <departure> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <day> to the <day> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <type> to the <type> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <time> to the <time> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <stay> to the <stay> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <internet> to the <internet> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <phone> to the <phone> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <choice> to the <choice> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <destination> to the <destination> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <name> to the <name> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <addr> to the <addr> key of the tokenizer
[2019-12-02 15:56:26,897 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <fee> to the <fee> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <area> to the <area> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <post> to the <post> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <price> to the <price> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <depart> to the <depart> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <id> to the <id> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <food> to the <food> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <stars> to the <stars> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <restaurant-inform> to the <restaurant-inform> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <restaurant-recommend> to the <restaurant-recommend> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <attraction-request> to the <attraction-request> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hotel-request> to the <hotel-request> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <general-welcome> to the <general-welcome> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <train-offerbook> to the <train-offerbook> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <booking-request> to the <booking-request> key of the tokenizer
[2019-12-02 15:56:26,898 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <restaurant-nooffer> to the <restaurant-nooffer> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hospital-inform> to the <hospital-inform> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <train-request> to the <train-request> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <train-nooffer> to the <train-nooffer> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <general-bye> to the <general-bye> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hotel-select> to the <hotel-select> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <taxi-inform> to the <taxi-inform> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <attraction-select> to the <attraction-select> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <attraction-nooffer> to the <attraction-nooffer> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <booking-inform> to the <booking-inform> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <train-offerbooked> to the <train-offerbooked> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <general-greet> to the <general-greet> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <train-inform> to the <train-inform> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <train-select> to the <train-select> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <booking-nobook> to the <booking-nobook> key of the tokenizer
[2019-12-02 15:56:26,899 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <police-inform> to the <police-inform> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <taxi-request> to the <taxi-request> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <attraction-inform> to the <attraction-inform> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <restaurant-select> to the <restaurant-select> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hotel-recommend> to the <hotel-recommend> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <booking-book> to the <booking-book> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hospital-request> to the <hospital-request> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <general-reqmore> to the <general-reqmore> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <restaurant-request> to the <restaurant-request> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hotel-nooffer> to the <hotel-nooffer> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hotel-inform> to the <hotel-inform> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <attraction-recommend> to the <attraction-recommend> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hotel> to the <hotel> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <police> to the <police> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <restaurant> to the <restaurant> key of the tokenizer
[2019-12-02 15:56:26,900 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <train> to the <train> key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <hospital> to the <hospital> key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <taxi> to the <taxi> key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning <attraction> to the <attraction> key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [restaurant_phone] to the [restaurant_phone] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [restaurant_reference] to the [restaurant_reference] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [restaurant_postcode] to the [restaurant_postcode] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [restaurant_addr] to the [restaurant_addr] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [restaurant_name] to the [restaurant_name] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hotel_phone] to the [hotel_phone] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hotel_reference] to the [hotel_reference] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hotel_postcode] to the [hotel_postcode] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hotel_addr] to the [hotel_addr] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hotel_name] to the [hotel_name] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [attraction_phone] to the [attraction_phone] key of the tokenizer
[2019-12-02 15:56:26,901 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [attraction_postcode] to the [attraction_postcode] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [attraction_addr] to the [attraction_addr] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [attraction_name] to the [attraction_name] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [train_reference] to the [train_reference] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [train_id] to the [train_id] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [taxi_phone] to the [taxi_phone] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hospital_phone] to the [hospital_phone] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hospital_postcode] to the [hospital_postcode] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hospital_addr] to the [hospital_addr] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [hospital_name] to the [hospital_name] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [police_phone] to the [police_phone] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [police_postcode] to the [police_postcode] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [police_addr] to the [police_addr] key of the tokenizer
[2019-12-02 15:56:26,902 PID:2591 INFO tokenization_utils.py add_special_tokens] Assigning [police_name] to the [police_name] key of the tokenizer
[2019-12-02 15:56:29,211 PID:2591 INFO base.py __init__] ExternalPolicy:
- agent = <convlab.agent.DialogAgent object at 0x7fa1a5266358>
- algorithm_spec = {'action_pdtype': 'Argmax',
 'action_policy': 'default',
 'e2e': {'max_history': 15,
         'model': 'gpt2_v4',
         'model_checkpoint': 'models/v4_1',
         'name': 'Transformer',
         'no_sample': 0,
         'top_p': 0.8},
 'name': 'ExternalPolicy'}
- name = ExternalPolicy
- net_spec = None
- memory_spec = {'max_size': 1, 'name': 'Replay'}
- body = body: {
  "agent": "<convlab.agent.DialogAgent object at 0x7fa1a5266358>",
  "env": "<convlab.env.multiwoz.MultiWozEnv object at 0x7fa1ee1532b0>",
  "aeb": "(0, 0, 0)",
  "a": 0,
  "e": 0,
  "b": 0,
  "explore_var": NaN,
  "entropy_coef": NaN,
  "loss": NaN,
  "mean_entropy": NaN,
  "mean_grad_norm": NaN,
  "ckpt_total_reward": NaN,
  "total_reward": 0,
  "total_reward_ma": NaN,
  "ma_window": 100,
  "best_reward_ma": -Infinity,
  "eval_reward_ma": NaN,
  "train_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, avg_return, avg_len, avg_success, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "eval_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, avg_return, avg_len, avg_success, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "observation_space": "Box(0,)",
  "action_space": "Discrete(0)",
  "observable_dim": {
    "state": 0
  },
  "state_dim": 0,
  "action_dim": 0,
  "is_discrete": true,
  "action_type": "discrete",
  "action_pdtype": "Argmax",
  "ActionPD": "<class 'convlab.lib.distribution.Argmax'>"
}
- action_pdtype = Argmax
- action_policy = <function default at 0x7fa1ed920c80>
- policy = <convlab.modules.e2e.multiwoz.Transformer.Transformer.Transformer object at 0x7fa1a5266780>
[2019-12-02 15:56:29,212 PID:2591 INFO __init__.py __init__] DialogAgent:
- spec = submission4
- a = 0
- agent_spec = {'algorithm': {'action_pdtype': 'Argmax',
               'action_policy': 'default',
               'e2e': {'max_history': 15,
                       'model': 'gpt2_v4',
                       'model_checkpoint': 'models/v4_1',
                       'name': 'Transformer',
                       'no_sample': 0,
                       'top_p': 0.8},
               'name': 'ExternalPolicy'},
 'memory': {'max_size': 1, 'name': 'Replay'},
 'name': 'DialogAgent'}
- name = DialogAgent
- nlu = None
- dst = None
- state_encoder = None
- action_decoder = None
- nlg = None
- body = body: {
  "agent": "<convlab.agent.DialogAgent object at 0x7fa1a5266358>",
  "env": "<convlab.env.multiwoz.MultiWozEnv object at 0x7fa1ee1532b0>",
  "aeb": "(0, 0, 0)",
  "a": 0,
  "e": 0,
  "b": 0,
  "explore_var": NaN,
  "entropy_coef": NaN,
  "loss": NaN,
  "mean_entropy": NaN,
  "mean_grad_norm": NaN,
  "ckpt_total_reward": NaN,
  "total_reward": 0,
  "total_reward_ma": NaN,
  "ma_window": 100,
  "best_reward_ma": -Infinity,
  "eval_reward_ma": NaN,
  "train_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, avg_return, avg_len, avg_success, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "eval_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, avg_return, avg_len, avg_success, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "observation_space": "Box(0,)",
  "action_space": "Discrete(0)",
  "observable_dim": {
    "state": 0
  },
  "state_dim": 0,
  "action_dim": 0,
  "is_discrete": true,
  "action_type": "discrete",
  "action_pdtype": "Argmax",
  "ActionPD": "<class 'convlab.lib.distribution.Argmax'>",
  "memory": "<convlab.agent.memory.replay.Replay object at 0x7fa1a52c3828>",
  "state": null,
  "encoded_state": null,
  "action": null
}
- algorithm = <convlab.agent.algorithm.external.ExternalPolicy object at 0x7fa1a52664e0>
- warmup_epi = -1
[2019-12-02 15:56:29,743 PID:2591 INFO archival.py load_archive] loading archive file /home/donghoon/.convlab/cache/35863b26c71cbed669f08d3e50030aed24e84e833eb523378b67226d137bedd9.f494dce99f30d2e1786136f7a0a487e643ee8ac430423828d1c0013526d1d7bd
[2019-12-02 15:56:29,743 PID:2591 INFO archival.py load_archive] extracting archive file /home/donghoon/.convlab/cache/35863b26c71cbed669f08d3e50030aed24e84e833eb523378b67226d137bedd9.f494dce99f30d2e1786136f7a0a487e643ee8ac430423828d1c0013526d1d7bd to temp dir /tmp/tmpl2d41hny
[2019-12-02 15:56:29,833 PID:2591 INFO params.py pop] type = default
[2019-12-02 15:56:29,833 PID:2591 INFO vocabulary.py from_files] Loading token dictionary from /tmp/tmpl2d41hny/vocabulary.
[2019-12-02 15:56:29,844 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.models.model.Model'> from params {'attention': {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400}, 'attention_for_intent': False, 'attention_for_tag': False, 'context_for_intent': True, 'context_for_tag': False, 'dropout': 0.3, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'}, 'include_start_end_transitions': False, 'intent_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'}, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}}, 'type': 'milu'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,844 PID:2591 INFO params.py pop] model.type = milu
[2019-12-02 15:56:29,844 PID:2591 INFO from_params.py from_params] instantiating class <class 'convlab.modules.nlu.multiwoz.milu.model.MILU'> from params {'attention': {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400}, 'attention_for_intent': False, 'attention_for_tag': False, 'context_for_intent': True, 'context_for_tag': False, 'dropout': 0.3, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'}, 'include_start_end_transitions': False, 'intent_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'}, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}}} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,845 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,845 PID:2591 INFO params.py pop] model.text_field_embedder.type = basic
[2019-12-02 15:56:29,845 PID:2591 INFO params.py pop] model.text_field_embedder.embedder_to_indexer_map = None
[2019-12-02 15:56:29,845 PID:2591 INFO params.py pop] model.text_field_embedder.allow_unmatched_keys = False
[2019-12-02 15:56:29,845 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,845 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.type = character_encoding
[2019-12-02 15:56:29,845 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 16
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
[2019-12-02 15:56:29,846 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
[2019-12-02 15:56:29,847 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
[2019-12-02 15:56:29,847 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
[2019-12-02 15:56:29,847 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'} and extras {}
[2019-12-02 15:56:29,847 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
[2019-12-02 15:56:29,847 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128} and extras {}
[2019-12-02 15:56:29,847 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 16
[2019-12-02 15:56:29,847 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 128
[2019-12-02 15:56:29,847 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
[2019-12-02 15:56:29,848 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
[2019-12-02 15:56:29,848 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
[2019-12-02 15:56:29,848 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
[2019-12-02 15:56:29,848 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,848 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.type = embedding
[2019-12-02 15:56:29,848 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.num_embeddings = None
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.embedding_dim = 50
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.pretrained_file = None
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.projection_dim = None
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.trainable = True
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.padding_index = None
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.max_norm = None
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.norm_type = 2.0
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False
[2019-12-02 15:56:29,849 PID:2591 INFO params.py pop] model.text_field_embedder.token_embedders.tokens.sparse = False
[2019-12-02 15:56:29,854 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,854 PID:2591 INFO params.py pop] model.encoder.type = lstm
[2019-12-02 15:56:29,855 PID:2591 INFO params.py pop] model.encoder.batch_first = True
[2019-12-02 15:56:29,855 PID:2591 INFO params.py pop] model.encoder.stateful = False
[2019-12-02 15:56:29,855 PID:2591 INFO params.py as_dict] Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
[2019-12-02 15:56:29,855 PID:2591 INFO params.py as_dict] CURRENTLY DEFINED PARAMETERS: 
[2019-12-02 15:56:29,855 PID:2591 INFO params.py log_recursively] model.encoder.bidirectional = True
[2019-12-02 15:56:29,855 PID:2591 INFO params.py log_recursively] model.encoder.dropout = 0.5
[2019-12-02 15:56:29,855 PID:2591 INFO params.py log_recursively] model.encoder.hidden_size = 200
[2019-12-02 15:56:29,855 PID:2591 INFO params.py log_recursively] model.encoder.input_size = 178
[2019-12-02 15:56:29,855 PID:2591 INFO params.py log_recursively] model.encoder.num_layers = 1
[2019-12-02 15:56:29,855 PID:2591 INFO params.py log_recursively] model.encoder.batch_first = True
[2019-12-02 15:56:29,859 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,859 PID:2591 INFO params.py pop] model.intent_encoder.type = lstm
[2019-12-02 15:56:29,859 PID:2591 INFO params.py pop] model.intent_encoder.batch_first = True
[2019-12-02 15:56:29,859 PID:2591 INFO params.py pop] model.intent_encoder.stateful = False
[2019-12-02 15:56:29,859 PID:2591 INFO params.py as_dict] Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
[2019-12-02 15:56:29,859 PID:2591 INFO params.py as_dict] CURRENTLY DEFINED PARAMETERS: 
[2019-12-02 15:56:29,859 PID:2591 INFO params.py log_recursively] model.intent_encoder.bidirectional = True
[2019-12-02 15:56:29,859 PID:2591 INFO params.py log_recursively] model.intent_encoder.dropout = 0.5
[2019-12-02 15:56:29,859 PID:2591 INFO params.py log_recursively] model.intent_encoder.hidden_size = 200
[2019-12-02 15:56:29,860 PID:2591 INFO params.py log_recursively] model.intent_encoder.input_size = 400
[2019-12-02 15:56:29,860 PID:2591 INFO params.py log_recursively] model.intent_encoder.num_layers = 1
[2019-12-02 15:56:29,860 PID:2591 INFO params.py log_recursively] model.intent_encoder.batch_first = True
[2019-12-02 15:56:29,866 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,866 PID:2591 INFO params.py pop] model.attention.type = bilinear
[2019-12-02 15:56:29,866 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.modules.attention.bilinear_attention.BilinearAttention'> from params {'matrix_dim': 400, 'vector_dim': 400} and extras {'vocab': Vocabulary with namespaces:  intent_labels, Size: 111 || labels, Size: 330 || tokens, Size: 18854 || token_characters, Size: 91 || Non Padded Namespaces: {'*labels', '*tags'}}
[2019-12-02 15:56:29,866 PID:2591 INFO params.py pop] model.attention.vector_dim = 400
[2019-12-02 15:56:29,866 PID:2591 INFO params.py pop] model.attention.matrix_dim = 400
[2019-12-02 15:56:29,866 PID:2591 INFO params.py pop] model.attention.normalize = True
[2019-12-02 15:56:29,867 PID:2591 INFO params.py pop] model.context_for_intent = True
[2019-12-02 15:56:29,867 PID:2591 INFO params.py pop] model.context_for_tag = False
[2019-12-02 15:56:29,867 PID:2591 INFO params.py pop] model.attention_for_intent = False
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.attention_for_tag = False
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.sequence_label_namespace = labels
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.intent_label_namespace = intent_labels
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.label_encoding = BIO
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.include_start_end_transitions = False
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.crf_decoding = False
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.constrain_crf_decoding = None
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.focal_loss_gamma = None
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.nongeneral_intent_weight = 5.0
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.num_train_examples = None
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.calculate_span_f1 = None
[2019-12-02 15:56:29,868 PID:2591 INFO params.py pop] model.dropout = 0.3
[2019-12-02 15:56:29,869 PID:2591 INFO params.py pop] model.verbose_metrics = False
[2019-12-02 15:56:29,869 PID:2591 INFO params.py pop] model.regularizer = [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]]
[2019-12-02 15:56:29,869 PID:2591 INFO params.py pop] model.regularizer.list.list.type = l2
[2019-12-02 15:56:29,926 PID:2591 INFO initializers.py __call__] Initializing parameters
[2019-12-02 15:56:29,926 PID:2591 INFO initializers.py __call__] Done initializing parameters; the following parameters are using their default initialization from their code
[2019-12-02 15:56:29,926 PID:2591 INFO initializers.py __call__]    attention._bias
[2019-12-02 15:56:29,926 PID:2591 INFO initializers.py __call__]    attention._weight_matrix
[2019-12-02 15:56:29,926 PID:2591 INFO initializers.py __call__]    encoder._module.bias_hh_l0
[2019-12-02 15:56:29,926 PID:2591 INFO initializers.py __call__]    encoder._module.bias_hh_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    encoder._module.bias_ih_l0
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    encoder._module.bias_ih_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    encoder._module.weight_hh_l0
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    encoder._module.weight_hh_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    encoder._module.weight_ih_l0
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    encoder._module.weight_ih_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_hh_l0
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_hh_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_ih_l0
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.bias_ih_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_hh_l0
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_hh_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_ih_l0
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_encoder._module.weight_ih_l0_reverse
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_projection_layer.bias
[2019-12-02 15:56:29,927 PID:2591 INFO initializers.py __call__]    intent_projection_layer.weight
[2019-12-02 15:56:29,928 PID:2591 INFO initializers.py __call__]    tag_projection_layer._module.bias
[2019-12-02 15:56:29,928 PID:2591 INFO initializers.py __call__]    tag_projection_layer._module.weight
[2019-12-02 15:56:29,928 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_token_characters._embedding._module.weight
[2019-12-02 15:56:29,928 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
[2019-12-02 15:56:29,928 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
[2019-12-02 15:56:29,928 PID:2591 INFO initializers.py __call__]    text_field_embedder.token_embedder_tokens.weight
[2019-12-02 15:56:29,934 PID:2591 INFO from_params.py from_params] instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'context_size': 5, 'token_indexers': {'token_characters': {'min_padding_length': 3, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'milu'} and extras {}
[2019-12-02 15:56:29,934 PID:2591 INFO params.py pop] dataset_reader.type = milu
[2019-12-02 15:56:29,934 PID:2591 INFO from_params.py from_params] instantiating class <class 'convlab.modules.nlu.multiwoz.milu.dataset_reader.MILUDatasetReader'> from params {'context_size': 5, 'token_indexers': {'token_characters': {'min_padding_length': 3, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras {}
[2019-12-02 15:56:29,934 PID:2591 INFO params.py pop] dataset_reader.context_size = 5
[2019-12-02 15:56:29,934 PID:2591 INFO params.py pop] dataset_reader.agent = None
[2019-12-02 15:56:29,935 PID:2591 INFO params.py pop] dataset_reader.random_context_size = True
[2019-12-02 15:56:29,935 PID:2591 INFO params.py pop] dataset_reader.token_delimiter = None
[2019-12-02 15:56:29,935 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'min_padding_length': 3, 'type': 'characters'} and extras {}
[2019-12-02 15:56:29,935 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.type = characters
[2019-12-02 15:56:29,935 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer from params {'min_padding_length': 3} and extras {}
[2019-12-02 15:56:29,935 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.namespace = token_characters
[2019-12-02 15:56:29,935 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.start_tokens = None
[2019-12-02 15:56:29,935 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.end_tokens = None
[2019-12-02 15:56:29,935 PID:2591 INFO params.py pop] dataset_reader.token_indexers.token_characters.min_padding_length = 3
[2019-12-02 15:56:29,935 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras {}
[2019-12-02 15:56:29,936 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.type = single_id
[2019-12-02 15:56:29,936 PID:2591 INFO from_params.py from_params] instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras {}
[2019-12-02 15:56:29,936 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.namespace = tokens
[2019-12-02 15:56:29,936 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.lowercase_tokens = True
[2019-12-02 15:56:29,936 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.start_tokens = None
[2019-12-02 15:56:29,936 PID:2591 INFO params.py pop] dataset_reader.token_indexers.tokens.end_tokens = None
[2019-12-02 15:56:29,936 PID:2591 INFO params.py pop] dataset_reader.lazy = False
[2019-12-02 15:56:29,970 PID:2591 INFO multiwoz.py __init__] MultiWozEnv:
- e = 0
- done = False
- env_spec = {'evaluator': {'name': 'MultiWozEvaluator'},
 'max_frame': 1000,
 'max_t': 40,
 'name': 'multiwoz',
 'nlg': {'is_user': True, 'name': 'MultiwozTemplateNLG'},
 'nlu': {'model_file': 'https://convlab.blob.core.windows.net/models/milu.tar.gz',
         'name': 'MILU'},
 'sys_policy': {'name': 'RuleBasedMultiwozBot'},
 'user_policy': {'name': 'UserPolicyAgendaMultiWoz'}}
- log_frequency = None
- frame_op = None
- frame_op_len = None
- normalize_state = False
- reward_scale = None
- num_envs = 1
- eval_frequency = 100
- name = multiwoz
- max_t = 40
- max_frame = 1000
- is_venv = False
- clock_speed = 1
- clock = <convlab.env.base.Clock object at 0x7fa1a5263e80>
- to_render = False
- action_dim = 0
- observation_dim = 0
- u_env = <convlab.env.multiwoz.MultiWozEnvironment object at 0x7fa188335908>
- evaluator = <convlab.evaluator.multiwoz.MultiWozEvaluator object at 0x7fa187f2aa20>
- observation_space = Box(0,)
- action_space = Discrete(0)
- observable_dim = {'state': 0}
- is_discrete = True
[2019-12-02 15:56:29,970 PID:2591 INFO logger.py info] Session:
- spec = submission4
- index = 0
- agent = <convlab.agent.DialogAgent object at 0x7fa1a5266358>
- env = <convlab.env.multiwoz.MultiWozEnv object at 0x7fa1ee1532b0>
- eval_env = <convlab.env.multiwoz.MultiWozEnv object at 0x7fa1a5263358>
- num_eval = 100
- warmup_epi = -1
[2019-12-02 15:56:29,995 PID:2591 ACT logger.py act] User action: {'Train-Inform': [['Day', 'thursday']]}
[2019-12-02 15:56:29,995 PID:2591 ACT logger.py act] Goal: {'train': {'info': {'destination': 'cambridge', 'day': 'thursday', 'arriveBy': '17:15', 'departure': 'cambridge'}, 'reqt': {'leaveAt': '?', 'price': '?'}, 'book': {'people': '5'}, 'booked': '?'}, 'restaurant': {'info': {'pricerange': 'cheap'}, 'reqt': {'address': '?'}}}
[2019-12-02 15:56:29,995 PID:2591 NL logger.py nl] User utterance: I need to travel on thursday .
[2019-12-02 15:56:29,995 PID:2591 ACT logger.py act] Inferred user action: I need to travel on thursday .
[2019-12-02 15:56:29,995 PID:2591 STATE logger.py state] Dialog state: I need to travel on thursday .
[2019-12-02 15:56:30,457 PID:2591 ACT logger.py act] System action: Where will you be departing from and where are you going?
[2019-12-02 15:56:30,458 PID:2591 NL logger.py nl] System utterance: Where will you be departing from and where are you going?
[2019-12-02 15:56:30,470 PID:2591 ACT logger.py act] Inferred system action: {'Train-Request': [['Depart', '?'], ['Dest', '?']]}
[2019-12-02 15:56:30,470 PID:2591 NL logger.py nl] User utterance: Yes I would like to go to cambridge please . Great I also need a train departs from cambridge .
[2019-12-02 15:56:30,470 PID:2591 ACT logger.py act] Inferred user action: Yes I would like to go to cambridge please . Great I also need a train departs from cambridge .
[2019-12-02 15:56:30,470 PID:2591 STATE logger.py state] Dialog state: Yes I would like to go to cambridge please . Great I also need a train departs from cambridge .
[2019-12-02 15:56:30,850 PID:2591 ACT logger.py act] System action: Where will you be departing from?
[2019-12-02 15:56:30,850 PID:2591 NL logger.py nl] System utterance: Where will you be departing from?
[2019-12-02 15:56:30,866 PID:2591 ACT logger.py act] Inferred system action: {'Train-Request': [['Depart', '?']]}
[2019-12-02 15:56:30,866 PID:2591 NL logger.py nl] User utterance: I ' m departing from cambridge .
[2019-12-02 15:56:30,866 PID:2591 ACT logger.py act] Inferred user action: I ' m departing from cambridge .
[2019-12-02 15:56:30,866 PID:2591 STATE logger.py state] Dialog state: I ' m departing from cambridge .
[2019-12-02 15:56:31,232 PID:2591 ACT logger.py act] System action: Where are you departing from?
[2019-12-02 15:56:31,232 PID:2591 NL logger.py nl] System utterance: Where are you departing from?
[2019-12-02 15:56:31,245 PID:2591 ACT logger.py act] Inferred system action: {'Train-Request': [['Depart', '?']]}
[2019-12-02 15:56:31,246 PID:2591 NL logger.py nl] User utterance: I will departing from cambridge .
[2019-12-02 15:56:31,246 PID:2591 ACT logger.py act] Inferred user action: I will departing from cambridge .
[2019-12-02 15:56:31,246 PID:2591 STATE logger.py state] Dialog state: I will departing from cambridge .
[2019-12-02 15:56:31,752 PID:2591 ACT logger.py act] System action: Do you have a time you 'd like to leave?
[2019-12-02 15:56:31,752 PID:2591 NL logger.py nl] System utterance: Do you have a time you 'd like to leave?
[2019-12-02 15:56:31,766 PID:2591 ACT logger.py act] Inferred system action: {'Train-Request': [['Leave', '?']]}
[2019-12-02 15:56:31,766 PID:2591 NL logger.py nl] User utterance: I need it to arrive by 17:15 .
[2019-12-02 15:56:31,766 PID:2591 ACT logger.py act] Inferred user action: I need it to arrive by 17:15 .
[2019-12-02 15:56:31,766 PID:2591 STATE logger.py state] Dialog state: I need it to arrive by 17:15 .
[2019-12-02 15:56:32,498 PID:2591 ACT logger.py act] System action: TR9119 will arrive at 24:55, would you like me to book you passage?
[2019-12-02 15:56:32,499 PID:2591 NL logger.py nl] System utterance: TR9119 will arrive at 24:55, would you like me to book you passage?
[2019-12-02 15:56:32,516 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Arrive', '24:55'], ['Id', 'TR9119']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:32,516 PID:2591 NL logger.py nl] User utterance: Do you have a train that arrives closer to 17:15 .
[2019-12-02 15:56:32,516 PID:2591 ACT logger.py act] Inferred user action: Do you have a train that arrives closer to 17:15 .
[2019-12-02 15:56:32,516 PID:2591 STATE logger.py state] Dialog state: Do you have a train that arrives closer to 17:15 .
[2019-12-02 15:56:33,266 PID:2591 ACT logger.py act] System action: TR9119 arrives by 24:55. Would you like me to book you passage?
[2019-12-02 15:56:33,267 PID:2591 NL logger.py nl] System utterance: TR9119 arrives by 24:55. Would you like me to book you passage?
[2019-12-02 15:56:33,285 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Id', 'TR9119'], ['Arrive', '24:55']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:33,285 PID:2591 NL logger.py nl] User utterance: I 'd like to arrive by 17:15 , do you have something close to that time ?
[2019-12-02 15:56:33,285 PID:2591 ACT logger.py act] Inferred user action: I 'd like to arrive by 17:15 , do you have something close to that time ?
[2019-12-02 15:56:33,285 PID:2591 STATE logger.py state] Dialog state: I 'd like to arrive by 17:15 , do you have something close to that time ?
[2019-12-02 15:56:34,146 PID:2591 ACT logger.py act] System action: The TR9119 arrives at 24:55. Would you like me to book that for you?
[2019-12-02 15:56:34,146 PID:2591 NL logger.py nl] System utterance: The TR9119 arrives at 24:55. Would you like me to book that for you?
[2019-12-02 15:56:34,167 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Arrive', '24:55'], ['Id', 'TR9119']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:34,167 PID:2591 NL logger.py nl] User utterance: I want to get there by 17:15 .
[2019-12-02 15:56:34,167 PID:2591 ACT logger.py act] Inferred user action: I want to get there by 17:15 .
[2019-12-02 15:56:34,167 PID:2591 STATE logger.py state] Dialog state: I want to get there by 17:15 .
[2019-12-02 15:56:35,141 PID:2591 ACT logger.py act] System action: I have train TR9119 arriving at 24:55. Would you like me to book that for you?
[2019-12-02 15:56:35,141 PID:2591 NL logger.py nl] System utterance: I have train TR9119 arriving at 24:55. Would you like me to book that for you?
[2019-12-02 15:56:35,162 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Id', 'TR9119'], ['Arrive', '24:55']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:35,162 PID:2591 NL logger.py nl] User utterance: I want to arrive by 17:15 .
[2019-12-02 15:56:35,162 PID:2591 ACT logger.py act] Inferred user action: I want to arrive by 17:15 .
[2019-12-02 15:56:35,162 PID:2591 STATE logger.py state] Dialog state: I want to arrive by 17:15 .
[2019-12-02 15:56:36,238 PID:2591 ACT logger.py act] System action: I have train TR9119 arriving at 24:55. Would you like me to book this?
[2019-12-02 15:56:36,238 PID:2591 NL logger.py nl] System utterance: I have train TR9119 arriving at 24:55. Would you like me to book this?
[2019-12-02 15:56:36,258 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Id', 'TR9119'], ['Arrive', '24:55']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:36,258 PID:2591 NL logger.py nl] User utterance: I want to get there by 17:15 .
[2019-12-02 15:56:36,258 PID:2591 ACT logger.py act] Inferred user action: I want to get there by 17:15 .
[2019-12-02 15:56:36,258 PID:2591 STATE logger.py state] Dialog state: I want to get there by 17:15 .
[2019-12-02 15:56:37,422 PID:2591 ACT logger.py act] System action: Train TR9119 will arrive by 24:55. Would you like me to book it for you?
[2019-12-02 15:56:37,422 PID:2591 NL logger.py nl] System utterance: Train TR9119 will arrive by 24:55. Would you like me to book it for you?
[2019-12-02 15:56:37,442 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Id', 'TR9119'], ['Arrive', '24:55']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:37,442 PID:2591 NL logger.py nl] User utterance: I 'd like to arrive by 17:15 .
[2019-12-02 15:56:37,442 PID:2591 ACT logger.py act] Inferred user action: I 'd like to arrive by 17:15 .
[2019-12-02 15:56:37,442 PID:2591 STATE logger.py state] Dialog state: I 'd like to arrive by 17:15 .
[2019-12-02 15:56:38,589 PID:2591 ACT logger.py act] System action: TR9119 will arrive at 24:55, would you like to book it?
[2019-12-02 15:56:38,589 PID:2591 NL logger.py nl] System utterance: TR9119 will arrive at 24:55, would you like to book it?
[2019-12-02 15:56:38,607 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Arrive', '24:55'], ['Id', 'TR9119']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:38,607 PID:2591 NL logger.py nl] User utterance: Do you have a train that arrives closer to 17:15 .
[2019-12-02 15:56:38,607 PID:2591 ACT logger.py act] Inferred user action: Do you have a train that arrives closer to 17:15 .
[2019-12-02 15:56:38,607 PID:2591 STATE logger.py state] Dialog state: Do you have a train that arrives closer to 17:15 .
[2019-12-02 15:56:39,859 PID:2591 ACT logger.py act] System action: TR9119 arrives at 24:55. Would you like to book it?
[2019-12-02 15:56:39,859 PID:2591 NL logger.py nl] System utterance: TR9119 arrives at 24:55. Would you like to book it?
[2019-12-02 15:56:39,876 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Id', 'TR9119'], ['Arrive', '24:55']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:39,876 PID:2591 NL logger.py nl] User utterance: I want to get there by 17:15 .
[2019-12-02 15:56:39,876 PID:2591 ACT logger.py act] Inferred user action: I want to get there by 17:15 .
[2019-12-02 15:56:39,876 PID:2591 STATE logger.py state] Dialog state: I want to get there by 17:15 .
[2019-12-02 15:56:40,787 PID:2591 ACT logger.py act] System action: How many tickets would you like to purchase?
[2019-12-02 15:56:40,787 PID:2591 NL logger.py nl] System utterance: How many tickets would you like to purchase?
[2019-12-02 15:56:40,802 PID:2591 ACT logger.py act] Inferred system action: {'Train-Request': [['People', '?']]}
[2019-12-02 15:56:40,802 PID:2591 NL logger.py nl] User utterance: Could you give me the price for that train ? Could you comfirm the departure time of that train ?
[2019-12-02 15:56:40,802 PID:2591 ACT logger.py act] Inferred user action: Could you give me the price for that train ? Could you comfirm the departure time of that train ?
[2019-12-02 15:56:40,802 PID:2591 STATE logger.py state] Dialog state: Could you give me the price for that train ? Could you comfirm the departure time of that train ?
[2019-12-02 15:56:41,890 PID:2591 ACT logger.py act] System action: It is 17.90 pounds.
[2019-12-02 15:56:41,890 PID:2591 NL logger.py nl] System utterance: It is 17.90 pounds.
[2019-12-02 15:56:41,904 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Ticket', '17.90 pounds']]}
[2019-12-02 15:56:41,904 PID:2591 NL logger.py nl] User utterance: What is the departure time ?
[2019-12-02 15:56:41,904 PID:2591 ACT logger.py act] Inferred user action: What is the departure time ?
[2019-12-02 15:56:41,904 PID:2591 STATE logger.py state] Dialog state: What is the departure time ?
[2019-12-02 15:56:43,027 PID:2591 ACT logger.py act] System action: It departs at 23:36.
[2019-12-02 15:56:43,027 PID:2591 NL logger.py nl] System utterance: It departs at 23:36.
[2019-12-02 15:56:43,040 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Leave', '23:36']]}
[2019-12-02 15:56:43,040 PID:2591 NL logger.py nl] User utterance: I need 5 tickets .
[2019-12-02 15:56:43,040 PID:2591 ACT logger.py act] Inferred user action: I need 5 tickets .
[2019-12-02 15:56:43,040 PID:2591 STATE logger.py state] Dialog state: I need 5 tickets .
[2019-12-02 15:56:44,307 PID:2591 ACT logger.py act] System action: I have booked that for you. Your reference number is 00000621 .
[2019-12-02 15:56:44,308 PID:2591 NL logger.py nl] System utterance: I have booked that for you. Your reference number is 00000621 .
[2019-12-02 15:56:44,324 PID:2591 ACT logger.py act] Inferred system action: {'Booking-Book': [['Ref', '00000621']]}
[2019-12-02 15:56:44,324 PID:2591 NL logger.py nl] User utterance: Thank you . That 's all I needed .
[2019-12-02 15:56:44,324 PID:2591 ACT logger.py act] Inferred user action: Thank you . That 's all I needed .
[2019-12-02 15:56:44,324 PID:2591 STATE logger.py state] Dialog state: Thank you . That 's all I needed .
[2019-12-02 15:56:45,532 PID:2591 ACT logger.py act] System action: Thanks for using our service. Have a great day.
[2019-12-02 15:56:45,532 PID:2591 NL logger.py nl] System utterance: Thanks for using our service. Have a great day.
[2019-12-02 15:56:45,547 PID:2591 ACT logger.py act] Inferred system action: {'general-bye': [['none', 'none']]}
[2019-12-02 15:56:45,547 PID:2591 NL logger.py nl] User utterance: I 'd like a cheap priced one .
[2019-12-02 15:56:45,547 PID:2591 ACT logger.py act] Inferred user action: I 'd like a cheap priced one .
[2019-12-02 15:56:45,547 PID:2591 STATE logger.py state] Dialog state: I 'd like a cheap priced one .
[2019-12-02 15:56:46,575 PID:2591 ACT logger.py act] System action: Thank you for using our service.
[2019-12-02 15:56:46,575 PID:2591 NL logger.py nl] System utterance: Thank you for using our service.
[2019-12-02 15:56:46,588 PID:2591 ACT logger.py act] Inferred system action: {'general-bye': [['none', 'none']]}
[2019-12-02 15:56:46,588 PID:2591 NL logger.py nl] User utterance: Please give me their address .
[2019-12-02 15:56:46,588 PID:2591 ACT logger.py act] Inferred user action: Please give me their address .
[2019-12-02 15:56:46,589 PID:2591 STATE logger.py state] Dialog state: Please give me their address .
[2019-12-02 15:56:47,763 PID:2591 ACT logger.py act] System action: The address is 88 Bishops St. in Cambridge.
[2019-12-02 15:56:47,763 PID:2591 NL logger.py nl] System utterance: The address is 88 Bishops St. in Cambridge.
[2019-12-02 15:56:47,776 PID:2591 ACT logger.py act] Inferred system action: {'Restaurant-Inform': [['Addr', '88 Bishops St.']]}
[2019-12-02 15:56:47,777 PID:2591 NL logger.py nl] User utterance: That 's all I need today . Thanks ! Bye !.
[2019-12-02 15:56:47,777 PID:2591 ACT logger.py act] Inferred user action: That 's all I need today . Thanks ! Bye !.
[2019-12-02 15:56:47,777 PID:2591 STATE logger.py state] Dialog state: That 's all I need today . Thanks ! Bye !.
[2019-12-02 15:56:47,777 PID:2591 NL logger.py nl] ---A dialog session is done---
[2019-12-02 15:56:47,791 PID:2591 ACT logger.py act] User action: {'Hotel-Inform': [['Stars', '4']]}
[2019-12-02 15:56:47,791 PID:2591 ACT logger.py act] Goal: {'hotel': {'info': {'type': 'guesthouse', 'area': 'centre', 'stars': '4'}, 'reqt': {'parking': '?'}}, 'train': {'info': {'destination': 'cambridge', 'day': 'monday', 'arriveBy': '20:00', 'departure': 'peterborough'}, 'reqt': {'trainID': '?'}}}
[2019-12-02 15:56:47,791 PID:2591 NL logger.py nl] User utterance: Are there any 4 stars available ?
[2019-12-02 15:56:47,791 PID:2591 ACT logger.py act] Inferred user action: Are there any 4 stars available ?
[2019-12-02 15:56:47,791 PID:2591 STATE logger.py state] Dialog state: Are there any 4 stars available ?
[2019-12-02 15:56:48,381 PID:2591 ACT logger.py act] System action: I have many options available. Is there a certain area of town you would like to stay?
[2019-12-02 15:56:48,381 PID:2591 NL logger.py nl] System utterance: I have many options available. Is there a certain area of town you would like to stay?
[2019-12-02 15:56:48,396 PID:2591 ACT logger.py act] Inferred system action: {'Hotel-Inform': [['Choice', 'many']], 'Hotel-Request': [['Area', '?']]}
[2019-12-02 15:56:48,396 PID:2591 NL logger.py nl] User utterance: I ' m looking for a hotel in the centre .
[2019-12-02 15:56:48,396 PID:2591 ACT logger.py act] Inferred user action: I ' m looking for a hotel in the centre .
[2019-12-02 15:56:48,397 PID:2591 STATE logger.py state] Dialog state: I ' m looking for a hotel in the centre .
[2019-12-02 15:56:48,955 PID:2591 ACT logger.py act] System action: There are many options available. Do you have a price range in mind?
[2019-12-02 15:56:48,956 PID:2591 NL logger.py nl] System utterance: There are many options available. Do you have a price range in mind?
[2019-12-02 15:56:48,974 PID:2591 ACT logger.py act] Inferred system action: {'Hotel-Inform': [['Choice', 'many']], 'Hotel-Request': [['Price', '?']]}
[2019-12-02 15:56:48,974 PID:2591 NL logger.py nl] User utterance: Do you have one that is a guesthouse ?
[2019-12-02 15:56:48,974 PID:2591 ACT logger.py act] Inferred user action: Do you have one that is a guesthouse ?
[2019-12-02 15:56:48,974 PID:2591 STATE logger.py state] Dialog state: Do you have one that is a guesthouse ?
[2019-12-02 15:56:49,555 PID:2591 ACT logger.py act] System action: There are many options. Do you have a preference on price?
[2019-12-02 15:56:49,555 PID:2591 NL logger.py nl] System utterance: There are many options. Do you have a preference on price?
[2019-12-02 15:56:49,574 PID:2591 ACT logger.py act] Inferred system action: {'Hotel-Inform': [['Choice', 'many']], 'Hotel-Request': [['Price', '?']]}
[2019-12-02 15:56:49,574 PID:2591 NL logger.py nl] User utterance: I would like to keep the price don't care .
[2019-12-02 15:56:49,574 PID:2591 ACT logger.py act] Inferred user action: I would like to keep the price don't care .
[2019-12-02 15:56:49,574 PID:2591 STATE logger.py state] Dialog state: I would like to keep the price don't care .
[2019-12-02 15:56:50,199 PID:2591 ACT logger.py act] System action: alexander bed and breakfast meets your criteria. Would you like to book a room?
[2019-12-02 15:56:50,199 PID:2591 NL logger.py nl] System utterance: alexander bed and breakfast meets your criteria. Would you like to book a room?
[2019-12-02 15:56:50,217 PID:2591 ACT logger.py act] Inferred system action: {'Hotel-Inform': [['Name', 'alexander bed and breakfast']], 'Booking-Inform': [['none', 'none']]}
[2019-12-02 15:56:50,217 PID:2591 NL logger.py nl] User utterance: Can you tell me if they have free parking ?
[2019-12-02 15:56:50,218 PID:2591 ACT logger.py act] Inferred user action: Can you tell me if they have free parking ?
[2019-12-02 15:56:50,218 PID:2591 STATE logger.py state] Dialog state: Can you tell me if they have free parking ?
[2019-12-02 15:56:50,851 PID:2591 ACT logger.py act] System action: They do. Would you like me to book that for you?
[2019-12-02 15:56:50,851 PID:2591 NL logger.py nl] System utterance: They do. Would you like me to book that for you?
[2019-12-02 15:56:50,868 PID:2591 ACT logger.py act] Inferred system action: {'Booking-Inform': [['none', 'none']]}
[2019-12-02 15:56:50,868 PID:2591 NL logger.py nl] User utterance: Do any / all of them have free parking as well ?
[2019-12-02 15:56:50,869 PID:2591 ACT logger.py act] Inferred user action: Do any / all of them have free parking as well ?
[2019-12-02 15:56:50,869 PID:2591 STATE logger.py state] Dialog state: Do any / all of them have free parking as well ?
[2019-12-02 15:56:51,351 PID:2591 ACT logger.py act] System action: Yes all of them do.
[2019-12-02 15:56:51,351 PID:2591 NL logger.py nl] System utterance: Yes all of them do.
[2019-12-02 15:56:51,365 PID:2591 ACT logger.py act] Inferred system action: {}
[2019-12-02 15:56:51,365 PID:2591 NL logger.py nl] User utterance: Can you tell me if they have free parking ?
[2019-12-02 15:56:51,365 PID:2591 ACT logger.py act] Inferred user action: Can you tell me if they have free parking ?
[2019-12-02 15:56:51,365 PID:2591 STATE logger.py state] Dialog state: Can you tell me if they have free parking ?
[2019-12-02 15:56:51,850 PID:2591 ACT logger.py act] System action: Yes they do.
[2019-12-02 15:56:51,850 PID:2591 NL logger.py nl] System utterance: Yes they do.
[2019-12-02 15:56:51,862 PID:2591 ACT logger.py act] Inferred system action: {'Hotel-Inform': [['Parking', 'none']]}
[2019-12-02 15:56:51,862 PID:2591 NL logger.py nl] User utterance: I will departing from peterborough . I 'd like to arrive by 20:00 . I would like to leave on monday. I need a train going to cambridge .
[2019-12-02 15:56:51,862 PID:2591 ACT logger.py act] Inferred user action: I will departing from peterborough . I 'd like to arrive by 20:00 . I would like to leave on monday. I need a train going to cambridge .
[2019-12-02 15:56:51,862 PID:2591 STATE logger.py state] Dialog state: I will departing from peterborough . I 'd like to arrive by 20:00 . I would like to leave on monday. I need a train going to cambridge .
[2019-12-02 15:56:52,743 PID:2591 ACT logger.py act] System action: The TR9493 will arrive by 24:55. Would you like to book it?
[2019-12-02 15:56:52,743 PID:2591 NL logger.py nl] System utterance: The TR9493 will arrive by 24:55. Would you like to book it?
[2019-12-02 15:56:52,763 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Id', 'TR9493'], ['Arrive', '24:55']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:52,764 PID:2591 NL logger.py nl] User utterance: Actually , I ' m all set . Thank you ! Bye !.
[2019-12-02 15:56:52,764 PID:2591 ACT logger.py act] Inferred user action: Actually , I ' m all set . Thank you ! Bye !.
[2019-12-02 15:56:52,764 PID:2591 STATE logger.py state] Dialog state: Actually , I ' m all set . Thank you ! Bye !.
[2019-12-02 15:56:52,764 PID:2591 NL logger.py nl] ---A dialog session is done---
[2019-12-02 15:56:52,769 PID:2591 ACT logger.py act] User action: {'Attraction-Inform': [['Type', 'college']]}
[2019-12-02 15:56:52,769 PID:2591 ACT logger.py act] Goal: {'attraction': {'info': {'type': 'college'}, 'reqt': {'address': '?', 'area': '?'}}}
[2019-12-02 15:56:52,769 PID:2591 NL logger.py nl] User utterance: I ' m looking for a college type attraction .
[2019-12-02 15:56:52,769 PID:2591 ACT logger.py act] Inferred user action: I ' m looking for a college type attraction .
[2019-12-02 15:56:52,769 PID:2591 STATE logger.py state] Dialog state: I ' m looking for a college type attraction .
[2019-12-02 15:56:53,241 PID:2591 ACT logger.py act] System action: There are 18 colleges in Cambridge. What area are you looking for?
[2019-12-02 15:56:53,241 PID:2591 NL logger.py nl] System utterance: There are 18 colleges in Cambridge. What area are you looking for?
[2019-12-02 15:56:53,254 PID:2591 ACT logger.py act] Inferred system action: {'Attraction-Inform': [['Choice', '18'], ['Type', 'colleges']], 'Attraction-Request': [['Area', '?']]}
[2019-12-02 15:56:53,254 PID:2591 NL logger.py nl] User utterance: Can you tell me what area it is located in ? Could I get the address for it ?
[2019-12-02 15:56:53,254 PID:2591 ACT logger.py act] Inferred user action: Can you tell me what area it is located in ? Could I get the address for it ?
[2019-12-02 15:56:53,254 PID:2591 STATE logger.py state] Dialog state: Can you tell me what area it is located in ? Could I get the address for it ?
[2019-12-02 15:56:53,548 PID:2591 ACT logger.py act] System action: christ's college is located on saint andrew's street .
[2019-12-02 15:56:53,549 PID:2591 NL logger.py nl] System utterance: christ's college is located on saint andrew's street .
[2019-12-02 15:56:53,566 PID:2591 ACT logger.py act] Inferred system action: {'Attraction-Inform': [['Addr', "saint andrew 's street"], ['Name', "christ 's college"]]}
[2019-12-02 15:56:53,567 PID:2591 NL logger.py nl] User utterance: Thank you . What 's the area ?
[2019-12-02 15:56:53,567 PID:2591 ACT logger.py act] Inferred user action: Thank you . What 's the area ?
[2019-12-02 15:56:53,567 PID:2591 STATE logger.py state] Dialog state: Thank you . What 's the area ?
[2019-12-02 15:56:54,052 PID:2591 ACT logger.py act] System action: christ's college is located in the centre. Would you like the address?
[2019-12-02 15:56:54,053 PID:2591 NL logger.py nl] System utterance: christ's college is located in the centre. Would you like the address?
[2019-12-02 15:56:54,071 PID:2591 ACT logger.py act] Inferred system action: {'Attraction-Inform': [['Area', 'centre'], ['Name', "christ 's college"]], 'general-reqmore': [['none', 'none']]}
[2019-12-02 15:56:54,071 PID:2591 NL logger.py nl] User utterance: You were great . Goodbye .
[2019-12-02 15:56:54,072 PID:2591 ACT logger.py act] Inferred user action: You were great . Goodbye .
[2019-12-02 15:56:54,072 PID:2591 STATE logger.py state] Dialog state: You were great . Goodbye .
[2019-12-02 15:56:54,072 PID:2591 NL logger.py nl] ---A dialog session is done---
[2019-12-02 15:56:54,086 PID:2591 ACT logger.py act] User action: {'Restaurant-Inform': [['Area', 'centre'], ['Price', 'expensive']]}
[2019-12-02 15:56:54,086 PID:2591 ACT logger.py act] Goal: {'restaurant': {'info': {'pricerange': 'expensive', 'area': 'centre'}, 'reqt': {'phone': '?'}}, 'train': {'info': {'destination': 'cambridge', 'day': 'tuesday', 'departure': 'stansted airport', 'leaveAt': '13:15'}, 'reqt': {'trainID': '?'}}}
[2019-12-02 15:56:54,086 PID:2591 NL logger.py nl] User utterance: I ' m so hungry - can you find me a place to eat in the city centre ? I want to find a expensive priced restaurant .
[2019-12-02 15:56:54,086 PID:2591 ACT logger.py act] Inferred user action: I ' m so hungry - can you find me a place to eat in the city centre ? I want to find a expensive priced restaurant .
[2019-12-02 15:56:54,086 PID:2591 STATE logger.py state] Dialog state: I ' m so hungry - can you find me a place to eat in the city centre ? I want to find a expensive priced restaurant .
[2019-12-02 15:56:54,543 PID:2591 ACT logger.py act] System action: I have many restaurants, what type of food are you looking for?
[2019-12-02 15:56:54,543 PID:2591 NL logger.py nl] System utterance: I have many restaurants, what type of food are you looking for?
[2019-12-02 15:56:54,560 PID:2591 ACT logger.py act] Inferred system action: {'Restaurant-Inform': [['Choice', 'many']], 'Restaurant-Request': [['Food', '?']]}
[2019-12-02 15:56:54,560 PID:2591 NL logger.py nl] User utterance: May I have their telephone number please ?
[2019-12-02 15:56:54,562 PID:2591 ACT logger.py act] Inferred user action: May I have their telephone number please ?
[2019-12-02 15:56:54,562 PID:2591 STATE logger.py state] Dialog state: May I have their telephone number please ?
[2019-12-02 15:56:54,887 PID:2591 ACT logger.py act] System action: curry garden phone number is 01223302330
[2019-12-02 15:56:54,887 PID:2591 NL logger.py nl] System utterance: curry garden phone number is 01223302330
[2019-12-02 15:56:54,903 PID:2591 ACT logger.py act] Inferred system action: {'Restaurant-Inform': [['Name', 'curry garden'], ['Phone', '01223302330']]}
[2019-12-02 15:56:54,903 PID:2591 NL logger.py nl] User utterance: I ' m departing from stansted airport . I ' m looking to travel on tuesday. I am leaving for cambridge. I would like to leave anytime after 13:15 .
[2019-12-02 15:56:54,904 PID:2591 ACT logger.py act] Inferred user action: I ' m departing from stansted airport . I ' m looking to travel on tuesday. I am leaving for cambridge. I would like to leave anytime after 13:15 .
[2019-12-02 15:56:54,904 PID:2591 STATE logger.py state] Dialog state: I ' m departing from stansted airport . I ' m looking to travel on tuesday. I am leaving for cambridge. I would like to leave anytime after 13:15 .
[2019-12-02 15:56:55,646 PID:2591 ACT logger.py act] System action: TR9536 leaves at 05:00.  Can I book you a seat?
[2019-12-02 15:56:55,646 PID:2591 NL logger.py nl] System utterance: TR9536 leaves at 05:00.  Can I book you a seat?
[2019-12-02 15:56:55,665 PID:2591 ACT logger.py act] Inferred system action: {'Train-Inform': [['Id', 'TR9536'], ['Leave', '05:00']], 'Train-OfferBook': [['none', 'none']]}
[2019-12-02 15:56:55,666 PID:2591 NL logger.py nl] User utterance: Actually , I ' m all set . Thank you ! Bye !.
[2019-12-02 15:56:55,666 PID:2591 ACT logger.py act] Inferred user action: Actually , I ' m all set . Thank you ! Bye !.
[2019-12-02 15:56:55,666 PID:2591 STATE logger.py state] Dialog state: Actually , I ' m all set . Thank you ! Bye !.
[2019-12-02 15:56:55,666 PID:2591 NL logger.py nl] ---A dialog session is done---
[2019-12-02 15:56:55,671 PID:2591 ACT logger.py act] User action: {'Restaurant-Inform': [['Food', 'italian'], ['Price', 'cheap']]}
[2019-12-02 15:56:55,671 PID:2591 ACT logger.py act] Goal: {'restaurant': {'info': {'food': 'italian', 'pricerange': 'cheap'}, 'reqt': {'phone': '?'}}}
[2019-12-02 15:56:55,671 PID:2591 NL logger.py nl] User utterance: How about a italian restaurant ? I am looking for a cheap restaurant .
[2019-12-02 15:56:55,671 PID:2591 ACT logger.py act] Inferred user action: How about a italian restaurant ? I am looking for a cheap restaurant .
[2019-12-02 15:56:55,671 PID:2591 STATE logger.py state] Dialog state: How about a italian restaurant ? I am looking for a cheap restaurant .
[2019-12-02 15:56:56,220 PID:2591 ACT logger.py act] System action: We have several. Is there a specific area of town you would like to dine in?
[2019-12-02 15:56:56,221 PID:2591 NL logger.py nl] System utterance: We have several. Is there a specific area of town you would like to dine in?
[2019-12-02 15:56:56,236 PID:2591 ACT logger.py act] Inferred system action: {'Restaurant-Inform': [['Choice', 'several']], 'Restaurant-Request': [['Area', '?']]}
[2019-12-02 15:56:56,237 PID:2591 NL logger.py nl] User utterance: I 'd like to be in the don't care please .
[2019-12-02 15:56:56,237 PID:2591 ACT logger.py act] Inferred user action: I 'd like to be in the don't care please .
[2019-12-02 15:56:56,237 PID:2591 STATE logger.py state] Dialog state: I 'd like to be in the don't care please .
[2019-12-02 15:56:56,730 PID:2591 ACT logger.py act] System action: pizza hut city centre is a nice place. Would you like me to make a reservation?
[2019-12-02 15:56:56,730 PID:2591 NL logger.py nl] System utterance: pizza hut city centre is a nice place. Would you like me to make a reservation?
[2019-12-02 15:56:56,751 PID:2591 ACT logger.py act] Inferred system action: {'Restaurant-Recommend': [['Name', 'pizza hut city centre']], 'Booking-Inform': [['none', 'none']]}
[2019-12-02 15:56:56,751 PID:2591 NL logger.py nl] User utterance: I would like their phone number .
[2019-12-02 15:56:56,751 PID:2591 ACT logger.py act] Inferred user action: I would like their phone number .
[2019-12-02 15:56:56,751 PID:2591 STATE logger.py state] Dialog state: I would like their phone number .
[2019-12-02 15:56:57,082 PID:2591 ACT logger.py act] System action: Their phone number is 01223323737 .
[2019-12-02 15:56:57,082 PID:2591 NL logger.py nl] System utterance: Their phone number is 01223323737 .
[2019-12-02 15:56:57,096 PID:2591 ACT logger.py act] Inferred system action: {'Restaurant-Inform': [['Phone', '01223323737']]}
[2019-12-02 15:56:57,096 PID:2591 NL logger.py nl] User utterance: That 's all I need today . Thanks ! Bye !.
[2019-12-02 15:56:57,097 PID:2591 ACT logger.py act] Inferred user action: That 's all I need today . Thanks ! Bye !.
[2019-12-02 15:56:57,097 PID:2591 STATE logger.py state] Dialog state: That 's all I need today . Thanks ! Bye !.
[2019-12-02 15:56:57,097 PID:2591 NL logger.py nl] ---A dialog session is done---
[2019-12-02 15:56:57,102 PID:2591 ACT logger.py act] User action: {'Hotel-Inform': [['Stars', '4']]}
[2019-12-02 15:56:57,102 PID:2591 ACT logger.py act] Goal: {'attraction': {'info': {'area': 'centre'}, 'reqt': {'postcode': '?', 'phone': '?'}}, 'hotel': {'info': {'area': 'centre', 'stars': '4'}, 'book': {'stay': '4', 'people': '1', 'day': 'sunday'}, 'booked': '?'}}
[2019-12-02 15:56:57,102 PID:2591 NL logger.py nl] User utterance: I want a place with a 4 star rating.
[2019-12-02 15:56:57,102 PID:2591 ACT logger.py act] Inferred user action: I want a place with a 4 star rating.
[2019-12-02 15:56:57,102 PID:2591 STATE logger.py state] Dialog state: I want a place with a 4 star rating.
[2019-12-02 15:56:57,723 PID:2591 ACT logger.py act] System action: There are many options to choose from.  Is there a certain area of town you would prefer?
[2019-12-02 15:56:57,723 PID:2591 NL logger.py nl] System utterance: There are many options to choose from.  Is there a certain area of town you would prefer?
[2019-12-02 15:56:57,739 PID:2591 ACT logger.py act] Inferred system action: {'Hotel-Inform': [['Choice', 'many']], 'Hotel-Request': [['Area', '?']]}
[2019-12-02 15:56:57,740 PID:2591 NL logger.py nl] User utterance: I need a place to stay in the centre please .
[2019-12-02 15:56:57,740 PID:2591 ACT logger.py act] Inferred user action: I need a place to stay in the centre please .
[2019-12-02 15:56:57,740 PID:2591 STATE logger.py state] Dialog state: I need a place to stay in the centre please .
[2019-12-02 15:56:58,331 PID:2591 ACT logger.py act] System action: There are many options to choose from. Do you have a price range in mind?
[2019-12-02 15:56:58,331 PID:2591 NL logger.py nl] System utterance: There are many options to choose from. Do you have a price range in mind?
[2019-12-02 15:56:58,351 PID:2591 ACT logger.py act] Inferred system action: {'Hotel-Inform': [['Choice', 'many']], 'Hotel-Request': [['Price', '?']]}
[2019-12-02 15:56:58,351 PID:2591 NL logger.py nl] User utterance: I also need a place to go in the centre .
[2019-12-02 15:56:58,351 PID:2591 ACT logger.py act] Inferred user action: I also need a place to go in the centre .
[2019-12-02 15:56:58,352 PID:2591 STATE logger.py state] Dialog state: I also need a place to go in the centre .
[2019-12-02 15:56:58,863 PID:2591 ACT logger.py act] System action: I have 44 attractions in that area. What kind of attraction would you like to see?
[2019-12-02 15:56:58,863 PID:2591 NL logger.py nl] System utterance: I have 44 attractions in that area. What kind of attraction would you like to see?
[2019-12-02 15:56:58,883 PID:2591 ACT logger.py act] Inferred system action: {'Attraction-Inform': [['Choice', '44']], 'Attraction-Request': [['Type', '?']]}
[2019-12-02 15:56:58,883 PID:2591 NL logger.py nl] User utterance: I was hoping to see local places while in cambridge . Some don't care would be great .
[2019-12-02 15:56:58,883 PID:2591 ACT logger.py act] Inferred user action: I was hoping to see local places while in cambridge . Some don't care would be great .
[2019-12-02 15:56:58,884 PID:2591 STATE logger.py state] Dialog state: I was hoping to see local places while in cambridge . Some don't care would be great .
[2019-12-02 15:56:59,163 PID:2591 ACT logger.py act] System action: How about adc theatre ?
[2019-12-02 15:56:59,163 PID:2591 NL logger.py nl] System utterance: How about adc theatre ?
[2019-12-02 15:56:59,178 PID:2591 ACT logger.py act] Inferred system action: {'Attraction-Recommend': [['Name', 'adc theatre']]}
[2019-12-02 15:56:59,178 PID:2591 NL logger.py nl] User utterance: Can you give me their phone number please ? I 'll need the postcode .
[2019-12-02 15:56:59,178 PID:2591 ACT logger.py act] Inferred user action: Can you give me their phone number please ? I 'll need the postcode .
[2019-12-02 15:56:59,179 PID:2591 STATE logger.py state] Dialog state: Can you give me their phone number please ? I 'll need the postcode .
[2019-12-02 15:56:59,595 PID:2591 ACT logger.py act] System action: The phone number is 01223300085 , postcode cb58as .
[2019-12-02 15:56:59,595 PID:2591 NL logger.py nl] System utterance: The phone number is 01223300085 , postcode cb58as .
[2019-12-02 15:56:59,613 PID:2591 ACT logger.py act] Inferred system action: {'Attraction-Inform': [['Phone', '01223300085'], ['Post', 'cb58as']]}
[2019-12-02 15:56:59,613 PID:2591 NL logger.py nl] User utterance: Sunday please . There will be 1 people . How about only 4 nights .
[2019-12-02 15:56:59,613 PID:2591 ACT logger.py act] Inferred user action: Sunday please . There will be 1 people . How about only 4 nights .
[2019-12-02 15:56:59,613 PID:2591 STATE logger.py state] Dialog state: Sunday please . There will be 1 people . How about only 4 nights .
[2019-12-02 15:57:00,290 PID:2591 ACT logger.py act] System action: Booking was successful. 
 Reference number is : [hotel_reference] . Is there anything else I can help you with?
[2019-12-02 15:57:00,290 PID:2591 NL logger.py nl] System utterance: Booking was successful. 
 Reference number is : [hotel_reference] . Is there anything else I can help you with?
[2019-12-02 15:57:00,313 PID:2591 ACT logger.py act] Inferred system action: {'general-reqmore': [['none', 'none']]}
[2019-12-02 15:57:00,313 PID:2591 NL logger.py nl] User utterance: I want to check in on sunday. There are 1 of us . How about 4 night ? Would that work ?
[2019-12-02 15:57:00,313 PID:2591 ACT logger.py act] Inferred user action: I want to check in on sunday. There are 1 of us . How about 4 night ? Would that work ?
[2019-12-02 15:57:00,313 PID:2591 STATE logger.py state] Dialog state: I want to check in on sunday. There are 1 of us . How about 4 night ? Would that work ?
[2019-12-02 15:57:00,803 PID:2591 ACT logger.py act] System action: I booked it for you and your reference number is [hotel_reference] .
[2019-12-02 15:57:00,803 PID:2591 NL logger.py nl] System utterance: I booked it for you and your reference number is [hotel_reference] .
[2019-12-02 15:57:00,825 PID:2591 ACT logger.py act] Inferred system action: {}
[2019-12-02 15:57:00,825 PID:2591 NL logger.py nl] User utterance: Great , can you book that for first day sunday please ? Yes , could you book the hotel room for me for 1 people ? I would like to book it for 4 nights please .
[2019-12-02 15:57:00,825 PID:2591 ACT logger.py act] Inferred user action: Great , can you book that for first day sunday please ? Yes , could you book the hotel room for me for 1 people ? I would like to book it for 4 nights please .
[2019-12-02 15:57:00,825 PID:2591 STATE logger.py state] Dialog state: Great , can you book that for first day sunday please ? Yes , could you book the hotel room for me for 1 people ? I would like to book it for 4 nights please .
[2019-12-02 15:57:01,462 PID:2591 ACT logger.py act] System action: Yes I have made those reservations and your reference number is [hotel_reference] .
[2019-12-02 15:57:01,462 PID:2591 NL logger.py nl] System utterance: Yes I have made those reservations and your reference number is [hotel_reference] .
[2019-12-02 15:57:01,488 PID:2591 ACT logger.py act] Inferred system action: {}
[2019-12-02 15:57:01,489 PID:2591 NL logger.py nl] User utterance: I want to check in on sunday. Yes , could you book the hotel room for me for 1 people ? What about 4 nights ?
[2019-12-02 15:57:01,489 PID:2591 ACT logger.py act] Inferred user action: I want to check in on sunday. Yes , could you book the hotel room for me for 1 people ? What about 4 nights ?
[2019-12-02 15:57:01,489 PID:2591 STATE logger.py state] Dialog state: I want to check in on sunday. Yes , could you book the hotel room for me for 1 people ? What about 4 nights ?
[2019-12-02 15:57:02,358 PID:2591 ACT logger.py act] System action: Booking was successful. Reference number is : 00000002 .
[2019-12-02 15:57:02,358 PID:2591 NL logger.py nl] System utterance: Booking was successful. Reference number is : 00000002 .
[2019-12-02 15:57:02,384 PID:2591 ACT logger.py act] Inferred system action: {'Booking-Book': [['Ref', '00000002']]}
[2019-12-02 15:57:02,384 PID:2591 NL logger.py nl] User utterance: Sunday please . There will be 1 of us . Can you try booking again for 4 nights ?
[2019-12-02 15:57:02,384 PID:2591 ACT logger.py act] Inferred user action: Sunday please . There will be 1 of us . Can you try booking again for 4 nights ?
[2019-12-02 15:57:02,384 PID:2591 STATE logger.py state] Dialog state: Sunday please . There will be 1 of us . Can you try booking again for 4 nights ?
[2019-12-02 15:57:03,395 PID:2591 INFO archival.py _cleanup_archive_dir] removing temporary unarchived model dir at /tmp/tmpl2d41hny
[2019-12-02 15:57:03,397 PID:2591 INFO archival.py _cleanup_archive_dir] removing temporary unarchived model dir at /tmp/tmplf3nj001
