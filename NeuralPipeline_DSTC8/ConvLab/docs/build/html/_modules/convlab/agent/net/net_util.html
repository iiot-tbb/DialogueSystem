

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>convlab.agent.net.net_util &mdash; ConvLab 0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> ConvLab
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"></div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">ConvLab</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../agent.html">convlab.agent</a> &raquo;</li>
        
      <li>convlab.agent.net.net_util</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for convlab.agent.net.net_util</h1><div class="highlight"><pre>
<span></span><span class="c1"># Modified by Microsoft Corporation.</span>
<span class="c1"># Licensed under the MIT license.</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">partial</span><span class="p">,</span> <span class="n">wraps</span>

<span class="kn">import</span> <span class="nn">pydash</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">convlab.lib</span> <span class="k">import</span> <span class="n">logger</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">util</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="c1"># register custom torch.optim</span>
<span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="s1">&#39;GlobalAdam&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">GlobalAdam</span><span class="p">)</span>


<div class="viewcode-block" id="NoOpLRScheduler"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.NoOpLRScheduler">[docs]</a><span class="k">class</span> <span class="nc">NoOpLRScheduler</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Symbolic LRScheduler class for API consistency&#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optim</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">optim</span>

<div class="viewcode-block" id="NoOpLRScheduler.step"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.NoOpLRScheduler.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="NoOpLRScheduler.get_lr"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.NoOpLRScheduler.get_lr">[docs]</a>    <span class="k">def</span> <span class="nf">get_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="s1">&#39;defaults&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">defaults</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># TODO retrieve lr more generally</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="build_fc_model"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.build_fc_model">[docs]</a><span class="k">def</span> <span class="nf">build_fc_model</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Build a full-connected model by interleaving nn.Linear and activation_fn&#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;dims need to at least contain input, output&#39;</span>
    <span class="c1"># shift dims and make pairs of (in, out) dims per layer</span>
    <span class="n">dim_pairs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dims</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">in_d</span><span class="p">,</span> <span class="n">out_d</span> <span class="ow">in</span> <span class="n">dim_pairs</span><span class="p">:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_d</span><span class="p">,</span> <span class="n">out_d</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span></div>


<div class="viewcode-block" id="get_nn_name"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_nn_name">[docs]</a><span class="k">def</span> <span class="nf">get_nn_name</span><span class="p">(</span><span class="n">uncased_name</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper to get the proper name in PyTorch nn given a case-insensitive name&#39;&#39;&#39;</span>
    <span class="k">for</span> <span class="n">nn_name</span> <span class="ow">in</span> <span class="n">nn</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">uncased_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="n">nn_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">nn_name</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Name </span><span class="si">{uncased_name}</span><span class="s1"> not found in </span><span class="si">{nn.__dict__}</span><span class="s1">&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="get_activation_fn"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_activation_fn">[docs]</a><span class="k">def</span> <span class="nf">get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper to generate activation function layers for net&#39;&#39;&#39;</span>
    <span class="n">ActivationClass</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">get_nn_name</span><span class="p">(</span><span class="n">activation</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">ActivationClass</span><span class="p">()</span></div>


<div class="viewcode-block" id="get_loss_fn"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_loss_fn">[docs]</a><span class="k">def</span> <span class="nf">get_loss_fn</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">loss_spec</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper to parse loss param and construct loss_fn for net&#39;&#39;&#39;</span>
    <span class="n">LossClass</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">get_nn_name</span><span class="p">(</span><span class="n">loss_spec</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]))</span>
    <span class="n">loss_spec</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">omit</span><span class="p">(</span><span class="n">loss_spec</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">LossClass</span><span class="p">(</span><span class="o">**</span><span class="n">loss_spec</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss_fn</span></div>


<div class="viewcode-block" id="get_lr_scheduler"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_lr_scheduler">[docs]</a><span class="k">def</span> <span class="nf">get_lr_scheduler</span><span class="p">(</span><span class="n">optim</span><span class="p">,</span> <span class="n">lr_scheduler_spec</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper to parse lr_scheduler param and construct Pytorch optim.lr_scheduler&#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">ps</span><span class="o">.</span><span class="n">is_empty</span><span class="p">(</span><span class="n">lr_scheduler_spec</span><span class="p">):</span>
        <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">NoOpLRScheduler</span><span class="p">(</span><span class="n">optim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">lr_scheduler_spec</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;LinearToZero&#39;</span><span class="p">:</span>
        <span class="n">LRSchedulerClass</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="s1">&#39;LambdaLR&#39;</span><span class="p">)</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lr_scheduler_spec</span><span class="p">[</span><span class="s1">&#39;frame&#39;</span><span class="p">])</span>
        <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">LRSchedulerClass</span><span class="p">(</span><span class="n">optim</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">x</span> <span class="o">/</span> <span class="n">frame</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">LRSchedulerClass</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">lr_scheduler_spec</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">])</span>
        <span class="n">lr_scheduler_spec</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">omit</span><span class="p">(</span><span class="n">lr_scheduler_spec</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">)</span>
        <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">LRSchedulerClass</span><span class="p">(</span><span class="n">optim</span><span class="p">,</span> <span class="o">**</span><span class="n">lr_scheduler_spec</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lr_scheduler</span></div>


<div class="viewcode-block" id="get_optim"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_optim">[docs]</a><span class="k">def</span> <span class="nf">get_optim</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">optim_spec</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper to parse optim param and construct optim for net&#39;&#39;&#39;</span>
    <span class="n">OptimClass</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optim_spec</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">])</span>
    <span class="n">optim_spec</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">omit</span><span class="p">(</span><span class="n">optim_spec</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">)</span>
    <span class="n">optim</span> <span class="o">=</span> <span class="n">OptimClass</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">**</span><span class="n">optim_spec</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optim</span></div>


<div class="viewcode-block" id="get_policy_out_dim"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_policy_out_dim">[docs]</a><span class="k">def</span> <span class="nf">get_policy_out_dim</span><span class="p">(</span><span class="n">body</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper method to construct the policy network out_dim for a body according to is_discrete, action_type&#39;&#39;&#39;</span>
    <span class="n">action_dim</span> <span class="o">=</span> <span class="n">body</span><span class="o">.</span><span class="n">action_dim</span>
    <span class="k">if</span> <span class="n">body</span><span class="o">.</span><span class="n">is_discrete</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">body</span><span class="o">.</span><span class="n">action_type</span> <span class="o">==</span> <span class="s1">&#39;multi_discrete&#39;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">ps</span><span class="o">.</span><span class="n">is_list</span><span class="p">(</span><span class="n">action_dim</span><span class="p">),</span> <span class="n">action_dim</span>
            <span class="n">policy_out_dim</span> <span class="o">=</span> <span class="n">action_dim</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">ps</span><span class="o">.</span><span class="n">is_integer</span><span class="p">(</span><span class="n">action_dim</span><span class="p">),</span> <span class="n">action_dim</span>
            <span class="n">policy_out_dim</span> <span class="o">=</span> <span class="n">action_dim</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">ps</span><span class="o">.</span><span class="n">is_integer</span><span class="p">(</span><span class="n">action_dim</span><span class="p">),</span> <span class="n">action_dim</span>
        <span class="k">if</span> <span class="n">action_dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># single action, use [loc, scale]</span>
            <span class="n">policy_out_dim</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># multi-action, use [locs], [scales]</span>
            <span class="n">policy_out_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">action_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">policy_out_dim</span></div>


<div class="viewcode-block" id="get_out_dim"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_out_dim">[docs]</a><span class="k">def</span> <span class="nf">get_out_dim</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="n">add_critic</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Construct the NetClass out_dim for a body according to is_discrete, action_type, and whether to add a critic unit&#39;&#39;&#39;</span>
    <span class="n">policy_out_dim</span> <span class="o">=</span> <span class="n">get_policy_out_dim</span><span class="p">(</span><span class="n">body</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">add_critic</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ps</span><span class="o">.</span><span class="n">is_list</span><span class="p">(</span><span class="n">policy_out_dim</span><span class="p">):</span>
            <span class="n">out_dim</span> <span class="o">=</span> <span class="n">policy_out_dim</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">policy_out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="n">policy_out_dim</span>
    <span class="k">return</span> <span class="n">out_dim</span></div>


<div class="viewcode-block" id="init_layers"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.init_layers">[docs]</a><span class="k">def</span> <span class="nf">init_layers</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">init_fn_name</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Primary method to initialize the weights of the layers of a network&#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">init_fn_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="c1"># get nonlinearity</span>
    <span class="n">nonlinearity</span> <span class="o">=</span> <span class="n">get_nn_name</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">hid_layers_activation</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;leakyrelu&#39;</span><span class="p">:</span>
        <span class="n">nonlinearity</span> <span class="o">=</span> <span class="s1">&#39;leaky_relu&#39;</span>  <span class="c1"># guard name</span>

    <span class="c1"># get init_fn and add arguments depending on nonlinearity</span>
    <span class="n">init_fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="p">,</span> <span class="n">init_fn_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;kaiming&#39;</span> <span class="ow">in</span> <span class="n">init_fn_name</span><span class="p">:</span>  <span class="c1"># has &#39;nonlinearity&#39; as arg</span>
        <span class="k">assert</span> <span class="n">nonlinearity</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="s1">&#39;leaky_relu&#39;</span><span class="p">],</span> <span class="n">f</span><span class="s1">&#39;Kaiming initialization not supported for </span><span class="si">{nonlinearity}</span><span class="s1">&#39;</span>
        <span class="n">init_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">init_fn</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">nonlinearity</span><span class="p">)</span>
    <span class="k">elif</span> <span class="s1">&#39;orthogonal&#39;</span> <span class="ow">in</span> <span class="n">init_fn_name</span> <span class="ow">or</span> <span class="s1">&#39;xavier&#39;</span> <span class="ow">in</span> <span class="n">init_fn_name</span><span class="p">:</span>  <span class="c1"># has &#39;gain&#39; as arg</span>
        <span class="n">gain</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">)</span>
        <span class="n">init_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">init_fn</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">gain</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="c1"># finally, apply init_params to each layer in its modules</span>
    <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">init_params</span><span class="p">,</span> <span class="n">init_fn</span><span class="o">=</span><span class="n">init_fn</span><span class="p">))</span></div>


<div class="viewcode-block" id="init_params"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.init_params">[docs]</a><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">init_fn</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Initialize module&#39;s weights using init_fn, and biases to 0.0&#39;&#39;&#39;</span>
    <span class="n">bias_init</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">classname</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_class_name</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;Net&#39;</span> <span class="ow">in</span> <span class="n">classname</span><span class="p">:</span>  <span class="c1"># skip if it&#39;s a net, not pytorch layer</span>
        <span class="k">pass</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">k</span> <span class="ow">in</span> <span class="n">classname</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;BatchNorm&#39;</span><span class="p">,</span> <span class="s1">&#39;Conv&#39;</span><span class="p">,</span> <span class="s1">&#39;Linear&#39;</span><span class="p">)):</span>
        <span class="n">init_fn</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">bias_init</span><span class="p">)</span>
    <span class="k">elif</span> <span class="s1">&#39;GRU&#39;</span> <span class="ow">in</span> <span class="n">classname</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="s1">&#39;weight&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">init_fn</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
            <span class="k">elif</span> <span class="s1">&#39;bias&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">bias_init</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">pass</span></div>


<span class="c1"># params methods</span>


<div class="viewcode-block" id="save"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.save">[docs]</a><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Save model weights to path&#39;&#39;&#39;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">util</span><span class="o">.</span><span class="n">smart_path</span><span class="p">(</span><span class="n">model_path</span><span class="p">))</span></div>


<div class="viewcode-block" id="save_algorithm"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.save_algorithm">[docs]</a><span class="k">def</span> <span class="nf">save_algorithm</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">ckpt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Save all the nets for an algorithm&#39;&#39;&#39;</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">agent</span>
    <span class="n">net_names</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">net_names</span>
    <span class="n">model_prepath</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">spec</span><span class="p">[</span><span class="s1">&#39;meta&#39;</span><span class="p">][</span><span class="s1">&#39;model_prepath&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">ckpt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model_prepath</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{model_prepath}</span><span class="s1">_ckpt-</span><span class="si">{ckpt}</span><span class="s1">&#39;</span>
    <span class="k">for</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">net_names</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">net_name</span><span class="p">)</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{model_prepath}</span><span class="s1">_</span><span class="si">{net_name}</span><span class="s1">_model.pt&#39;</span>
        <span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
        <span class="n">optim_name</span> <span class="o">=</span> <span class="n">net_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;net&#39;</span><span class="p">,</span> <span class="s1">&#39;optim&#39;</span><span class="p">)</span>
        <span class="n">optim</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">optim_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># only trainable net has optim</span>
            <span class="n">optim_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{model_prepath}</span><span class="s1">_</span><span class="si">{net_name}</span><span class="s1">_optim.pt&#39;</span>
            <span class="n">save</span><span class="p">(</span><span class="n">optim</span><span class="p">,</span> <span class="n">optim_path</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Saved algorithm {util.get_class_name(algorithm)} nets </span><span class="si">{net_names}</span><span class="s1"> to </span><span class="si">{model_prepath}</span><span class="s1">_*.pt&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="load"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.load">[docs]</a><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Save model weights from a path into a net module&#39;&#39;&#39;</span>
    <span class="n">device</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">smart_path</span><span class="p">(</span><span class="n">model_path</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span></div>


<div class="viewcode-block" id="load_algorithm"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.load_algorithm">[docs]</a><span class="k">def</span> <span class="nf">load_algorithm</span><span class="p">(</span><span class="n">algorithm</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Save all the nets for an algorithm&#39;&#39;&#39;</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">agent</span>
    <span class="n">net_names</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">net_names</span>
    <span class="k">if</span> <span class="n">util</span><span class="o">.</span><span class="n">in_eval_lab_modes</span><span class="p">():</span>
        <span class="c1"># load specific model in eval mode</span>
        <span class="n">model_prepath</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">spec</span><span class="p">[</span><span class="s1">&#39;meta&#39;</span><span class="p">][</span><span class="s1">&#39;eval_model_prepath&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_prepath</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">spec</span><span class="p">[</span><span class="s1">&#39;meta&#39;</span><span class="p">][</span><span class="s1">&#39;model_prepath&#39;</span><span class="p">]</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Loading algorithm {util.get_class_name(algorithm)} nets </span><span class="si">{net_names}</span><span class="s1"> from </span><span class="si">{model_prepath}</span><span class="s1">_*.pt&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">net_names</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">net_name</span><span class="p">)</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{model_prepath}</span><span class="s1">_</span><span class="si">{net_name}</span><span class="s1">_model.pt&#39;</span>
        <span class="n">load</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
        <span class="n">optim_name</span> <span class="o">=</span> <span class="n">net_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;net&#39;</span><span class="p">,</span> <span class="s1">&#39;optim&#39;</span><span class="p">)</span>
        <span class="n">optim</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">optim_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># only trainable net has optim</span>
            <span class="n">optim_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{model_prepath}</span><span class="s1">_</span><span class="si">{net_name}</span><span class="s1">_optim.pt&#39;</span>
            <span class="n">load</span><span class="p">(</span><span class="n">optim</span><span class="p">,</span> <span class="n">optim_path</span><span class="p">)</span></div>


<div class="viewcode-block" id="copy"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.copy">[docs]</a><span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="n">src_net</span><span class="p">,</span> <span class="n">tar_net</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Copy model weights from src to target&#39;&#39;&#39;</span>
    <span class="n">tar_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">src_net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span></div>


<div class="viewcode-block" id="polyak_update"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.polyak_update">[docs]</a><span class="k">def</span> <span class="nf">polyak_update</span><span class="p">(</span><span class="n">src_net</span><span class="p">,</span> <span class="n">tar_net</span><span class="p">,</span> <span class="n">old_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Polyak weight update to update a target tar_net, retain old weights by its ratio, i.e.</span>
<span class="sd">    target &lt;- old_ratio * source + (1 - old_ratio) * target</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">for</span> <span class="n">src_param</span><span class="p">,</span> <span class="n">tar_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">src_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">tar_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
        <span class="n">tar_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">old_ratio</span> <span class="o">*</span> <span class="n">src_param</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">old_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="n">tar_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span></div>


<div class="viewcode-block" id="to_check_train_step"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.to_check_train_step">[docs]</a><span class="k">def</span> <span class="nf">to_check_train_step</span><span class="p">():</span>
    <span class="sd">&#39;&#39;&#39;Condition for running assert_trained&#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PY_ENV&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span> <span class="ow">or</span> <span class="n">util</span><span class="o">.</span><span class="n">get_lab_mode</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;dev&#39;</span></div>


<div class="viewcode-block" id="dev_check_train_step"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.dev_check_train_step">[docs]</a><span class="k">def</span> <span class="nf">dev_check_train_step</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Decorator to check if net.train_step actually updates the network weights properly</span>
<span class="sd">    Triggers only if to_check_train_step is True (dev/test mode)</span>
<span class="sd">    @example</span>

<span class="sd">    @net_util.dev_check_train_step</span>
<span class="sd">    def train_step(self, ...):</span>
<span class="sd">        ...</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nd">@wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">check_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">to_check_train_step</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">net</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># first arg self</span>
        <span class="c1"># get pre-update parameters to compare</span>
        <span class="n">pre_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>

        <span class="c1"># run train_step, get loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="n">loss</span>

        <span class="c1"># get post-update parameters to compare</span>
        <span class="n">post_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="c1"># if loss is 0, there should be no updates</span>
            <span class="c1"># TODO if without momentum, parameters should not change too</span>
            <span class="k">for</span> <span class="n">p_name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
                <span class="k">assert</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># check parameter updates</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">assert</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span> <span class="k">for</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pre_params</span><span class="p">,</span> <span class="n">post_params</span><span class="p">)),</span> <span class="n">f</span><span class="s1">&#39;Model parameter is not updated in train_step(), check if your tensor is detached from graph. Loss: </span><span class="si">{loss:g}</span><span class="s1">&#39;</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Model parameter is updated in train_step(). Loss: </span><span class="si">{loss: g}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PY_ENV&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
                    <span class="c1"># raise error if in unit test</span>
                    <span class="k">raise</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

            <span class="c1"># check grad norms</span>
            <span class="n">min_norm</span><span class="p">,</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1e5</span>
            <span class="k">for</span> <span class="n">p_name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
                    <span class="k">assert</span> <span class="n">min_norm</span> <span class="o">&lt;</span> <span class="n">grad_norm</span> <span class="o">&lt;</span> <span class="n">max_norm</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;Gradient norm for </span><span class="si">{p_name}</span><span class="s1"> is </span><span class="si">{grad_norm:g}</span><span class="s1">, fails the extreme value check </span><span class="si">{min_norm}</span><span class="s1"> &lt; grad_norm &lt; </span><span class="si">{max_norm}</span><span class="s1">. Loss: </span><span class="si">{loss:g}</span><span class="s1">. Check your network and loss computation.&#39;</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Gradient norms passed value check.&#39;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Passed network parameter update check.&#39;</span><span class="p">)</span>
        <span class="c1"># store grad norms for debugging</span>
        <span class="n">net</span><span class="o">.</span><span class="n">store_grad_norms</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>
    <span class="k">return</span> <span class="n">check_fn</span></div>


<div class="viewcode-block" id="get_grad_norms"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.get_grad_norms">[docs]</a><span class="k">def</span> <span class="nf">get_grad_norms</span><span class="p">(</span><span class="n">algorithm</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Gather all the net&#39;s grad norms of an algorithm for debugging&#39;&#39;&#39;</span>
    <span class="n">grad_norms</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">net_names</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">net_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">net</span><span class="o">.</span><span class="n">grad_norms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad_norms</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">grad_norms</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grad_norms</span></div>


<div class="viewcode-block" id="init_global_nets"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.init_global_nets">[docs]</a><span class="k">def</span> <span class="nf">init_global_nets</span><span class="p">(</span><span class="n">algorithm</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Initialize global_nets for Hogwild using an identical instance of an algorithm from an isolated Session</span>
<span class="sd">    in spec.meta.distributed, specify either:</span>
<span class="sd">    - &#39;shared&#39;: global network parameter is shared all the time. In this mode, algorithm local network will be replaced directly by global_net via overriding by identify attribute name</span>
<span class="sd">    - &#39;synced&#39;: global network parameter is periodically synced to local network after each gradient push. In this mode, algorithm will keep a separate reference to `global_{net}` for each of its network</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">dist_mode</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">spec</span><span class="p">[</span><span class="s1">&#39;meta&#39;</span><span class="p">][</span><span class="s1">&#39;distributed&#39;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">dist_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;shared&#39;</span><span class="p">,</span> <span class="s1">&#39;synced&#39;</span><span class="p">),</span> <span class="n">f</span><span class="s1">&#39;Unrecognized distributed mode&#39;</span>
    <span class="n">global_nets</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">net_names</span><span class="p">:</span>
        <span class="n">optim_name</span> <span class="o">=</span> <span class="n">net_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;net&#39;</span><span class="p">,</span> <span class="s1">&#39;optim&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">optim_name</span><span class="p">):</span>  <span class="c1"># only for trainable network, i.e. has an optim</span>
            <span class="k">continue</span>
        <span class="n">g_net</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">net_name</span><span class="p">)</span>
        <span class="n">g_net</span><span class="o">.</span><span class="n">share_memory</span><span class="p">()</span>  <span class="c1"># make net global</span>
        <span class="k">if</span> <span class="n">dist_mode</span> <span class="o">==</span> <span class="s1">&#39;shared&#39;</span><span class="p">:</span>  <span class="c1"># use the same name to override the local net</span>
            <span class="n">global_nets</span><span class="p">[</span><span class="n">net_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">g_net</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># keep a separate reference for syncing</span>
            <span class="n">global_nets</span><span class="p">[</span><span class="n">f</span><span class="s1">&#39;global_</span><span class="si">{net_name}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">g_net</span>
        <span class="c1"># if optim is Global, set to override the local optim and its scheduler</span>
        <span class="n">optim</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">optim_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;Global&#39;</span> <span class="ow">in</span> <span class="n">util</span><span class="o">.</span><span class="n">get_class_name</span><span class="p">(</span><span class="n">optim</span><span class="p">):</span>
            <span class="n">optim</span><span class="o">.</span><span class="n">share_memory</span><span class="p">()</span>  <span class="c1"># make optim global</span>
            <span class="n">global_nets</span><span class="p">[</span><span class="n">optim_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">optim</span>
            <span class="n">lr_scheduler_name</span> <span class="o">=</span> <span class="n">net_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;net&#39;</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">)</span>
            <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">lr_scheduler_name</span><span class="p">)</span>
            <span class="n">global_nets</span><span class="p">[</span><span class="n">lr_scheduler_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scheduler</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Initialized global_nets attr {list(global_nets.keys())} for Hogwild&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">global_nets</span></div>


<div class="viewcode-block" id="set_global_nets"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.set_global_nets">[docs]</a><span class="k">def</span> <span class="nf">set_global_nets</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">global_nets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;For Hogwild, set attr built in init_global_nets above. Use in algorithm init.&#39;&#39;&#39;</span>
    <span class="c1"># set attr first so algorithm always has self.global_{net} to pass into train_step</span>
    <span class="k">for</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">net_names</span><span class="p">:</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;global_</span><span class="si">{net_name}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># set attr created in init_global_nets</span>
    <span class="k">if</span> <span class="n">global_nets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">util</span><span class="o">.</span><span class="n">set_attr</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">global_nets</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Set global_nets attr {list(global_nets.keys())} for Hogwild&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="push_global_grads"><a class="viewcode-back" href="../../../../convlab.agent.net.html#convlab.agent.net.net_util.push_global_grads">[docs]</a><span class="k">def</span> <span class="nf">push_global_grads</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">global_net</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Push gradients to global_net, call inside train_step between loss.backward() and optim.step()&#39;&#39;&#39;</span>
    <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">global_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">global_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
        <span class="k">if</span> <span class="n">global_param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>  <span class="c1"># quick skip</span>
        <span class="n">global_param</span><span class="o">.</span><span class="n">_grad</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, ConvLab

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>